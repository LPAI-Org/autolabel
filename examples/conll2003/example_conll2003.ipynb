{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fe6e643-9453-4381-9445-bd471685fb96",
   "metadata": {},
   "source": [
    "## Exploring the CONLL 2003 dataset using Autolabel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80110a5b-2b3e-45e2-a2da-f6fa00200dff",
   "metadata": {},
   "source": [
    "#### Setup the API Keys for providers that you want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92993c83-4473-4e05-9510-f543b070c7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# provide your own OpenAI API key here\n",
    "os.environ['OPENAI_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c246f85",
   "metadata": {},
   "source": [
    "#### Install the autolabel library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc181e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'refuel-autolabel[openai]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5b1630",
   "metadata": {},
   "source": [
    "#### Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9382044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autolabel import get_data\n",
    "\n",
    "get_data('conll2003')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72542ae",
   "metadata": {},
   "source": [
    "This downloads two datasets:\n",
    "* `test.csv`: This is the larger dataset we are trying to label using LLMs\n",
    "* `seed.csv`: This is a small dataset where we already have human-provided labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb92a79",
   "metadata": {},
   "source": [
    "## Start the labeling process!\n",
    "\n",
    "Labeling with Autolabel is a 3-step process:\n",
    "* First, we specify a labeling configuration (see `config.json` below)\n",
    "* Next, we do a dry-run on our dataset using the LLM specified in `config.json` by running `agent.plan`\n",
    "* Finally, we run the labeling with `agent.run`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b014d1-f45c-4479-9acc-0d20870b1786",
   "metadata": {},
   "source": [
    "### First labeling run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c093fe91-3508-4140-8bd6-217034e3cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from autolabel import LabelingAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c93fae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the config\n",
    "with open('config_conll2003.json', 'r') as f:\n",
    "     config = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dfc1f9",
   "metadata": {},
   "source": [
    "Let's review the configuration file below. You'll notice the following useful keys:\n",
    "* `task_type`: `named_entity_recognition` (since it's a named entity recognition task)\n",
    "* `model`: `{'provider': 'openai', 'name': 'gpt-3.5-turbo'}` (use a specific OpenAI model)\n",
    "* `prompt.task_guidelines`: `'You are an expert at extracting Person, Organization, Location, and Miscellaneous entities...` (how we describe the task to the LLM)\n",
    "* `prompt.labels`: `[\n",
    "            \"Location\",\n",
    "            \"Organization\",\n",
    "            \"Person\",\n",
    "            \"Miscellaneous\"\n",
    "        ]` (the full list of labels to choose from)\n",
    "* `prompt.few_shot_num`: 3 (how many labeled examples to provide to the LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "450ad645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_name': 'PersonLocationOrgMiscNER',\n",
       " 'task_type': 'named_entity_recognition',\n",
       " 'dataset': {'label_column': 'CategorizedLabels',\n",
       "  'text_column': 'example',\n",
       "  'delimiter': ','},\n",
       " 'model': {'provider': 'openai', 'name': 'gpt-3.5-turbo-instruct'},\n",
       " 'prompt': {'task_guidelines': 'You are an expert at extracting Person, Organization, Location, and Miscellaneous entities from text. Your job is to extract named entities mentioned in text, and classify them into one of the following categories.\\nCategories:\\n{labels}\\n ',\n",
       "  'labels': ['Location', 'Organization', 'Person', 'Miscellaneous'],\n",
       "  'example_template': 'Example: {example}\\nOutput:\\n{CategorizedLabels}',\n",
       "  'few_shot_examples': 'seed.csv',\n",
       "  'few_shot_selection': 'semantic_similarity',\n",
       "  'few_shot_num': 5}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acb4a3de-fa84-4b94-b17a-7a6fac892a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-19 18:25:53 autolabel.models.openai WARNING: Current engine: completion\n"
     ]
    }
   ],
   "source": [
    "# create an agent for labeling\n",
    "agent = LabelingAgent(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92667a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7128509649264d84b867629d77c342e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┌──────────────────────────┬─────────┐\n",
       "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Total Estimated Cost     </span>│<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> $4.8981 </span>│\n",
       "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Number of Examples       </span>│<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> 2000    </span>│\n",
       "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Average cost per example </span>│<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> $0.0024 </span>│\n",
       "└──────────────────────────┴─────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┌──────────────────────────┬─────────┐\n",
       "│\u001b[1;35m \u001b[0m\u001b[1;35mTotal Estimated Cost    \u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;32m \u001b[0m\u001b[1;32m$4.8981\u001b[0m\u001b[1;32m \u001b[0m│\n",
       "│\u001b[1;35m \u001b[0m\u001b[1;35mNumber of Examples      \u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;32m \u001b[0m\u001b[1;32m2000   \u001b[0m\u001b[1;32m \u001b[0m│\n",
       "│\u001b[1;35m \u001b[0m\u001b[1;35mAverage cost per example\u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;32m \u001b[0m\u001b[1;32m$0.0024\u001b[0m\u001b[1;32m \u001b[0m│\n",
       "└──────────────────────────┴─────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────────────────── </span>Prompt Example<span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ──────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────────────────── \u001b[0mPrompt Example\u001b[92m ──────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">You are an expert at extracting Person, Organization, Location, and Miscellaneous entities from text. Your job is \n",
       "to extract named entities mentioned in text, and classify them into one of the following categories.\n",
       "Categories:\n",
       "Location\n",
       "Organization\n",
       "Person\n",
       "Miscellaneous\n",
       " \n",
       "\n",
       "You will return the answer in CSV format, with two columns seperated by the % character. First column is the \n",
       "extracted entity and second column is the category. Rows in the CSV are separated by new line character.\n",
       "\n",
       "Some examples with their output answers are provided below:\n",
       "\n",
       "Example: MUNICH , Germany <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1996</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>\n",
       "Output:\n",
       "MUNICH%Location\n",
       "Germany%Location\n",
       "\n",
       "Example: PARIS <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1996</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>\n",
       "Output:\n",
       "PARIS%Location\n",
       "\n",
       "Example: PARIS <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1996</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>\n",
       "Output:\n",
       "PARIS%Location\n",
       "\n",
       "Example: COPENHAGEN <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1996</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>\n",
       "Output:\n",
       "COPENHAGEN%Location\n",
       "\n",
       "Example: MANTUA , Italy <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1996</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>\n",
       "Output:\n",
       "Italy%Location\n",
       "\n",
       "Now I want you to label the following example:\n",
       "Example: SOCCER - JAPAN GET LUCKY WIN , CHINA IN SURPRISE DEFEAT .\n",
       "Output:\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "You are an expert at extracting Person, Organization, Location, and Miscellaneous entities from text. Your job is \n",
       "to extract named entities mentioned in text, and classify them into one of the following categories.\n",
       "Categories:\n",
       "Location\n",
       "Organization\n",
       "Person\n",
       "Miscellaneous\n",
       " \n",
       "\n",
       "You will return the answer in CSV format, with two columns seperated by the % character. First column is the \n",
       "extracted entity and second column is the category. Rows in the CSV are separated by new line character.\n",
       "\n",
       "Some examples with their output answers are provided below:\n",
       "\n",
       "Example: MUNICH , Germany \u001b[1;36m1996\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m\n",
       "Output:\n",
       "MUNICH%Location\n",
       "Germany%Location\n",
       "\n",
       "Example: PARIS \u001b[1;36m1996\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m\n",
       "Output:\n",
       "PARIS%Location\n",
       "\n",
       "Example: PARIS \u001b[1;36m1996\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m\n",
       "Output:\n",
       "PARIS%Location\n",
       "\n",
       "Example: COPENHAGEN \u001b[1;36m1996\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m\n",
       "Output:\n",
       "COPENHAGEN%Location\n",
       "\n",
       "Example: MANTUA , Italy \u001b[1;36m1996\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m\n",
       "Output:\n",
       "Italy%Location\n",
       "\n",
       "Now I want you to label the following example:\n",
       "Example: SOCCER - JAPAN GET LUCKY WIN , CHINA IN SURPRISE DEFEAT .\n",
       "Output:\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dry-run -- this tells us how much this will cost and shows an example prompt\n",
    "from autolabel import AutolabelDataset\n",
    "ds = AutolabelDataset(\"test.csv\", config=config)\n",
    "agent.plan(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd703025-54d8-4349-b0d6-736d2380e966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b147317426d4425f980a241adba967a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Actual Cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4602</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Actual Cost: \u001b[1;36m0.4602\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> support </span>┃<span style=\"font-weight: bold\"> completion_rate </span>┃<span style=\"font-weight: bold\"> f1_exact </span>┃<span style=\"font-weight: bold\"> f1_strict </span>┃<span style=\"font-weight: bold\"> f1_partial </span>┃<span style=\"font-weight: bold\"> f1_ent_type </span>┃<span style=\"font-weight: bold\"> accuracy </span>┃\n",
       "┡━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> 1000    </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> 1.0             </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> 0.8028   </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> 0.6747    </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> 0.8161     </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> 0.6861      </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> 0.776    </span>│\n",
       "└─────────┴─────────────────┴──────────┴───────────┴────────────┴─────────────┴──────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1msupport\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mcompletion_rate\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mf1_exact\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mf1_strict\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mf1_partial\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mf1_ent_type\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1maccuracy\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━┩\n",
       "│\u001b[1;36m \u001b[0m\u001b[1;36m1000   \u001b[0m\u001b[1;36m \u001b[0m│\u001b[1;36m \u001b[0m\u001b[1;36m1.0            \u001b[0m\u001b[1;36m \u001b[0m│\u001b[1;36m \u001b[0m\u001b[1;36m0.8028  \u001b[0m\u001b[1;36m \u001b[0m│\u001b[1;36m \u001b[0m\u001b[1;36m0.6747   \u001b[0m\u001b[1;36m \u001b[0m│\u001b[1;36m \u001b[0m\u001b[1;36m0.8161    \u001b[0m\u001b[1;36m \u001b[0m│\u001b[1;36m \u001b[0m\u001b[1;36m0.6861     \u001b[0m\u001b[1;36m \u001b[0m│\u001b[1;36m \u001b[0m\u001b[1;36m0.776   \u001b[0m\u001b[1;36m \u001b[0m│\n",
       "└─────────┴─────────────────┴──────────┴───────────┴────────────┴─────────────┴──────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now, do the actual labeling\n",
    "ds = agent.run(ds, max_items=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e1901d",
   "metadata": {},
   "source": [
    "We are at 88.9% accuracy when labeling the first 100 examples. Let's see if we can use confidence scores to improve accuracy further by removing the less confident examples from our labeled set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7645ab",
   "metadata": {},
   "source": [
    "### Compute confidence scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f2fb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start computing confidence scores (using Refuel's LLMs)\n",
    "os.environ['REFUEL_API_KEY'] = 'xxxxxxxxxxxxxxxxx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbc1264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set `compute_confidence` -> True\n",
    "config[\"model\"][\"compute_confidence\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1998f5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = LabelingAgent(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119e6f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autolabel import AutolabelDataset\n",
    "ds = AutolabelDataset(\"test.csv\", config=config)\n",
    "agent.plan(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c74705",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = agent.run(ds, max_items=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2aa2f55",
   "metadata": {},
   "source": [
    "Looking at the table above, we can see that if we set the confidence threshold at `0.7573`, we are able to label at 82% accuracy and getting a completion rate of 74%. This means, we would ignore all the data points where confidence score is less than `0.7656` (which would end up being around 26% of all samples). This would, however, guarantee a very high quality labeled dataset for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254d179b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = agent.run(ds, max_items=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf226cd",
   "metadata": {},
   "source": [
    "Looking at the table above, we can see that if we set the confidence threshold at `0.7314`, we are able to label at 90.45% accuracy and getting a completion rate of 80%. This means, we would ignore all the data points where confidence score is less than `0.7314` (which would end up being around 20% of all samples). This would, however, guarantee a very high quality labeled dataset for us. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
