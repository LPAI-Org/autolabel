{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fe6e643-9453-4381-9445-bd471685fb96",
   "metadata": {},
   "source": [
    "## Exploring the SciQ dataset using Autolabel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80110a5b-2b3e-45e2-a2da-f6fa00200dff",
   "metadata": {},
   "source": [
    "#### Setup the API Keys for providers that you want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92993c83-4473-4e05-9510-f543b070c7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# provide your own OpenAI API key here\n",
    "os.environ['OPENAI_API_KEY'] = 'sk-'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c246f85",
   "metadata": {},
   "source": [
    "#### Install the autolabel library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc181e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: refuel-autolabel[openai] in /opt/homebrew/lib/python3.10/site-packages (0.0.1)\n",
      "Requirement already satisfied: loguru>=0.5.0 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (0.5.3)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (1.23.3)\n",
      "Requirement already satisfied: requests>=2.27.0 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (2.28.1)\n",
      "Requirement already satisfied: datasets>=2.7.0 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (2.11.0)\n",
      "Requirement already satisfied: langchain>=0.0.190 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (0.0.191)\n",
      "Requirement already satisfied: nervaluate>=0.1.8 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (0.1.8)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (1.5.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (1.1.2)\n",
      "Requirement already satisfied: tenacity>=8.2.2 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (8.2.2)\n",
      "Requirement already satisfied: SQLAlchemy==1.4.47 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (1.4.47)\n",
      "Requirement already satisfied: regex>=2023.6.3 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (2023.6.3)\n",
      "Requirement already satisfied: rich>=13.3.5 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (13.4.1)\n",
      "Requirement already satisfied: scipy>=1.10.1 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (1.10.1)\n",
      "Requirement already satisfied: pydantic>=1.10.9 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (1.10.9)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (1.13.0)\n",
      "Requirement already satisfied: matplotlib>=3.5.0 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (3.6.0)\n",
      "Requirement already satisfied: wget>=3.2 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (3.2)\n",
      "Requirement already satisfied: openai>=0.27.4 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (0.27.6)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (0.3.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/homebrew/lib/python3.10/site-packages (from datasets>=2.7.0->refuel-autolabel[openai]) (9.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/homebrew/lib/python3.10/site-packages (from datasets>=2.7.0->refuel-autolabel[openai]) (0.3.5.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/homebrew/lib/python3.10/site-packages (from datasets>=2.7.0->refuel-autolabel[openai]) (4.64.1)\n",
      "Requirement already satisfied: xxhash in /opt/homebrew/lib/python3.10/site-packages (from datasets>=2.7.0->refuel-autolabel[openai]) (3.1.0)\n",
      "Requirement already satisfied: multiprocess in /opt/homebrew/lib/python3.10/site-packages (from datasets>=2.7.0->refuel-autolabel[openai]) (0.70.13)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/homebrew/lib/python3.10/site-packages (from datasets>=2.7.0->refuel-autolabel[openai]) (2022.10.0)\n",
      "Requirement already satisfied: aiohttp in /opt/homebrew/lib/python3.10/site-packages (from datasets>=2.7.0->refuel-autolabel[openai]) (3.8.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /opt/homebrew/lib/python3.10/site-packages (from datasets>=2.7.0->refuel-autolabel[openai]) (0.14.1)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/lib/python3.10/site-packages (from datasets>=2.7.0->refuel-autolabel[openai]) (21.3)\n",
      "Requirement already satisfied: responses<0.19 in /opt/homebrew/lib/python3.10/site-packages (from datasets>=2.7.0->refuel-autolabel[openai]) (0.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/lib/python3.10/site-packages (from datasets>=2.7.0->refuel-autolabel[openai]) (6.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/homebrew/lib/python3.10/site-packages (from langchain>=0.0.190->refuel-autolabel[openai]) (4.0.2)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /opt/homebrew/lib/python3.10/site-packages (from langchain>=0.0.190->refuel-autolabel[openai]) (0.5.7)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /opt/homebrew/lib/python3.10/site-packages (from langchain>=0.0.190->refuel-autolabel[openai]) (2.8.4)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /opt/homebrew/lib/python3.10/site-packages (from langchain>=0.0.190->refuel-autolabel[openai]) (1.2.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.10/site-packages (from matplotlib>=3.5.0->refuel-autolabel[openai]) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/lib/python3.10/site-packages (from matplotlib>=3.5.0->refuel-autolabel[openai]) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/lib/python3.10/site-packages (from matplotlib>=3.5.0->refuel-autolabel[openai]) (4.37.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/homebrew/lib/python3.10/site-packages (from matplotlib>=3.5.0->refuel-autolabel[openai]) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/homebrew/lib/python3.10/site-packages (from matplotlib>=3.5.0->refuel-autolabel[openai]) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/homebrew/lib/python3.10/site-packages (from matplotlib>=3.5.0->refuel-autolabel[openai]) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/homebrew/lib/python3.10/site-packages (from matplotlib>=3.5.0->refuel-autolabel[openai]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.10/site-packages (from pandas>=1.3.0->refuel-autolabel[openai]) (2022.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/homebrew/lib/python3.10/site-packages (from pydantic>=1.10.9->refuel-autolabel[openai]) (4.3.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/homebrew/lib/python3.10/site-packages (from requests>=2.27.0->refuel-autolabel[openai]) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.10/site-packages (from requests>=2.27.0->refuel-autolabel[openai]) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/lib/python3.10/site-packages (from requests>=2.27.0->refuel-autolabel[openai]) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.10/site-packages (from requests>=2.27.0->refuel-autolabel[openai]) (2022.9.14)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/homebrew/lib/python3.10/site-packages (from rich>=13.3.5->refuel-autolabel[openai]) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/homebrew/lib/python3.10/site-packages (from rich>=13.3.5->refuel-autolabel[openai]) (2.15.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn>=1.0.0->refuel-autolabel[openai]) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn>=1.0.0->refuel-autolabel[openai]) (3.1.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.0->refuel-autolabel[openai]) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.0->refuel-autolabel[openai]) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.0->refuel-autolabel[openai]) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.0->refuel-autolabel[openai]) (1.3.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.0->refuel-autolabel[openai]) (1.2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /opt/homebrew/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.190->refuel-autolabel[openai]) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /opt/homebrew/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.190->refuel-autolabel[openai]) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.190->refuel-autolabel[openai]) (0.8.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets>=2.7.0->refuel-autolabel[openai]) (3.8.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/homebrew/lib/python3.10/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=13.3.5->refuel-autolabel[openai]) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.5.0->refuel-autolabel[openai]) (1.12.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/lib/python3.10/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.190->refuel-autolabel[openai]) (0.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install 'refuel-autolabel[openai]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ced632",
   "metadata": {},
   "source": [
    "#### Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bdeefe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autolabel import get_data\n",
    "\n",
    "get_data('belebele')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f17787",
   "metadata": {},
   "source": [
    "This downloads two datasets:\n",
    "* `test.csv`: This is the larger dataset we are trying to label using LLMs\n",
    "* `seed.csv`: This is a small dataset where we already have human-provided labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b014d1-f45c-4479-9acc-0d20870b1786",
   "metadata": {},
   "source": [
    "## Start the labeling process!\n",
    "\n",
    "Labeling with Autolabel is a 3-step process:\n",
    "* First, we specify a labeling configuration (see `config.json` below)\n",
    "* Next, we do a dry-run on our dataset using the LLM specified in `config.json` by running `agent.plan`\n",
    "* Finally, we run the labeling with `agent.run`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c093fe91-3508-4140-8bd6-217034e3cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from autolabel import LabelingAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c93fae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the config\n",
    "with open('config_belebele.json', 'r') as f:\n",
    "     config = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0983618",
   "metadata": {},
   "source": [
    "Let's review the configuration file below. You'll notice the following useful keys:\n",
    "* `task_type`: `question_answering` (since it's a question answering task)\n",
    "* `model`: `{'provider': 'openai', 'name': 'gpt-3.5-turbo'}` (use a specific OpenAI model)\n",
    "* `prompt.task_guidelines`: `'You are an expert at answer science questions...` (how we describe the task to the LLM)\n",
    "* `prompt.few_shot_num`: 10 (how many labeled examples to provide to the LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08a1f895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_name': 'QuestionAnsweringTrivia',\n",
       " 'task_type': 'question_answering',\n",
       " 'dataset': {'label_column': 'answer', 'delimiter': ','},\n",
       " 'model': {'provider': 'openai', 'name': 'gpt-3.5-turbo'},\n",
       " 'prompt': {'task_guidelines': 'You are an expert at answering questions based on context. Your job is to answer the given question, using the options provided for each question. Choose the best answer for the question from among the options provided',\n",
       "  'example_template': 'Question: {question}\\nOptions: {options}\\nAnswer: {answer}',\n",
       "  'few_shot_examples': 'seed.csv',\n",
       "  'few_shot_selection': 'semantic_similarity',\n",
       "  'few_shot_num': 10}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acb4a3de-fa84-4b94-b17a-7a6fac892a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an agent for labeling\n",
    "agent = LabelingAgent(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92667a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b8b03ea24a4e0ca7b12a41cd8d90a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┌──────────────────────────┬─────────┐\n",
       "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Total Estimated Cost     </span>│<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> $3.8817 </span>│\n",
       "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Number of Examples       </span>│<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> 800     </span>│\n",
       "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Average cost per example </span>│<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> $0.0049 </span>│\n",
       "└──────────────────────────┴─────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┌──────────────────────────┬─────────┐\n",
       "│\u001b[1;35m \u001b[0m\u001b[1;35mTotal Estimated Cost    \u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;32m \u001b[0m\u001b[1;32m$3.8817\u001b[0m\u001b[1;32m \u001b[0m│\n",
       "│\u001b[1;35m \u001b[0m\u001b[1;35mNumber of Examples      \u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;32m \u001b[0m\u001b[1;32m800    \u001b[0m\u001b[1;32m \u001b[0m│\n",
       "│\u001b[1;35m \u001b[0m\u001b[1;35mAverage cost per example\u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;32m \u001b[0m\u001b[1;32m$0.0049\u001b[0m\u001b[1;32m \u001b[0m│\n",
       "└──────────────────────────┴─────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────────────────── </span>Prompt Example<span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ──────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────────────────── \u001b[0mPrompt Example\u001b[92m ──────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">You are an expert at answering questions based on context. Your job is to answer the given question, using the \n",
       "options provided for each question. Choose the best answer for the question from among the options provided\n",
       "\n",
       "You will return the answer one element: <span style=\"color: #008000; text-decoration-color: #008000\">\"the correct label\"</span>\n",
       "\n",
       "\n",
       "Some examples with their output answers are provided below:\n",
       "\n",
       "Question: Context: <span style=\"color: #008000; text-decoration-color: #008000\">\"Widespread looting reportedly continued overnight, as law enforcement officers were not present</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">on Bishkek's streets. Bishkek was described as sinking into a state of \"\"anarchy\"\" by one observer, as gangs of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">people roamed the streets and plundered stores of consumer goods. Several Bishkek residents blamed protesters from </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the south for the lawlessness.\"</span> Question: Who did several of Bishkek’s residents think were responsible for the \n",
       "looting?\n",
       "Options: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Law enforcement officers'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Store owners'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Protesters'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Teenagers'</span><span style=\"font-weight: bold\">]</span>\n",
       "Answer: Protesters\n",
       "\n",
       "Question: Context: During his trip, Iwasaki ran into trouble on many occasions. He was robbed by pirates, attacked \n",
       "in Tibet by a rabid dog, escaped marriage in Nepal and was arrested in India. Question: Who attacked Iwasaki?\n",
       "Options: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'His potential spouse'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Pirates'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'A dog'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Police'</span><span style=\"font-weight: bold\">]</span>\n",
       "Answer: A dog\n",
       "\n",
       "Question: Context: Organisers of the protest said about <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">000</span> people turned up in German cities such as Berlin, \n",
       "Cologne, Hamburg, and Hanover. In Berlin, police estimated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span> protestors. Protests also took place in Paris, \n",
       "Sofia in Bulgaria, Vilnius in Lithuania, Valetta in Malta, Tallinn in Estonia, and Edinburgh and Glasgow in \n",
       "Scotland. In London, about <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">200</span> people protested outside some major copyright holders' offices. Last month, there \n",
       "were major protests in Poland when that country signed ACTA, which has led to the Polish government deciding not to\n",
       "ratify the agreement, for now. Latvia and Slovakia have both delayed the process of joining ACTA. Question: In \n",
       "response to the protests, which country did not move forward with their signed ACTA agreement?\n",
       "Options: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Germany'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Poland'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Scotland'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Lithuania'</span><span style=\"font-weight: bold\">]</span>\n",
       "Answer: Poland\n",
       "\n",
       "Question: Context: <span style=\"color: #008000; text-decoration-color: #008000\">\"The celebrations started with a special show by the world-renowned group Cirque du Soleil. It </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">was followed by the Istanbul State Symphony Orchestra, a Janissary band, and the singers Fatih Erkoç and Müslüm </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Gürses. Then Whirling Dervishes took to the stage. Turkish diva Sezen Aksu performed with the Italian tenor </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Alessandro Safina and Greek singer Haris Alexiou. To finish, Turkish dance group Fire of Anatolia performed the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">show \"\"Troy\"\".\"</span> Question: What was the second-last performance of the evening?\n",
       "Options: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Sezen Aksu, Alessandro Safina and Haris Alexiou'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Fire of Anatolia'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Whirling Dervishes'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Fatih Erkoç</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and Müslüm Gürses'</span><span style=\"font-weight: bold\">]</span>\n",
       "Answer: Sezen Aksu, Alessandro Safina and Haris Alexiou\n",
       "\n",
       "Question: Context: The terrified King Louis XVI, Queen Marie Antoinette their two young children <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> year old Marie\n",
       "Therese and four year old Louis-Charles<span style=\"font-weight: bold\">)</span> and the King's sister, Madam Elizabeth, on the 6th October <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1789</span> were \n",
       "forced back to Paris from Versailles by a mob of market women. In a carriage, they traveled back to Paris \n",
       "surrounded by a mob of people screaming and shouting threats against the King and Queen. The mob of people forced \n",
       "the King And Queen to have their carriage windows wide open. At one point a member of the mob waved the head of a \n",
       "royal guard killed at Versailles in front of the terrified Queen. Question: Which of the following was not forced \n",
       "upon the King and the Queen by the mob?\n",
       "Options: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'The opening of their carriage windows'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'An abrupt exit from Versailles '</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'A viewing of the guard’s </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">beheading'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'A trip back to Paris'</span><span style=\"font-weight: bold\">]</span>\n",
       "Answer: A viewing of the guard’s beheading\n",
       "\n",
       "Question: Context: Martelly swore in a new Provisional Electoral Council <span style=\"font-weight: bold\">(</span>CEP<span style=\"font-weight: bold\">)</span> of nine members yesterday. It is \n",
       "Martelly's fifth CEP in four years. Last month a presidential commission recommended the prior CEP's resignation as\n",
       "part of a package of measures to move the country towards new elections. The commission was Martelly's response to \n",
       "widespread anti-regime protests that started in October. The sometimes-violent protests were triggered by failure \n",
       "to hold elections, some due since <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2011</span>. Question: Which statement regarding the protests is not true?\n",
       "Options: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'The presidential commission was a response to the protests'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Overdue elections triggered the protests'</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'Protests demanded the resignation of the prior CEP'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The protests were sometimes violent'</span><span style=\"font-weight: bold\">]</span>\n",
       "Answer: Protests demanded the resignation of the prior CEP\n",
       "\n",
       "Question: Context: A doctor who worked at Children's Hospital of Pittsburgh, Pennsylvania will be charged with \n",
       "aggravated murder after her mother was found dead in the trunk of her car Wednesday, authorities in Ohio say. Dr. \n",
       "Malar Balasubramanian, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29</span>, was found in Blue Ash, Ohio, a suburb approximately <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> miles north of Cincinnati lying \n",
       "on the ground beside the road in a T-shirt and underwear in an apparently heavily medicated state. She directed \n",
       "officers to her black Oldsmobile Intrigue which was <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span> feet away. There, they found the body of Saroja \n",
       "Balasubramanian, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">53</span>, covered with blood-stained blankets. Police said that the body appeared to have been there for\n",
       "about a day. Question: How was Dr. Malar Balasubramanian related to Saroja Balasubramanian?\n",
       "Options: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Sister'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Daughter'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Mother'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Aunt'</span><span style=\"font-weight: bold\">]</span>\n",
       "Answer: Daughter\n",
       "\n",
       "Question: Context: <span style=\"color: #008000; text-decoration-color: #008000\">\"The Irish government is stressing the urgency of parliamentary legislation to rectify the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">situation. \"\"It is now important from both a public health and criminal justice perspective that the legislation be</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enacted as soon as possible\"\", said a government spokesperson. The Health Minister expressed concern both for the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">welfare of individuals taking advantage of the temporary legality of the substances involved, and for drug-related </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">convictions handed down since the now-unconstitutional changes came into effect.\"</span> Question: What is the Irish \n",
       "government planning to do?\n",
       "Options: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Hand out convictions to drug offenders'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Introduce more stringent laws on the permissibility of drugs'</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'Relax laws on the permissibility of drugs'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Decriminalise drugs'</span><span style=\"font-weight: bold\">]</span>\n",
       "Answer: Introduce more stringent laws on the permissibility of drugs\n",
       "\n",
       "Question: Context: News spread in the Red Lake community today as funerals for Jeff Weise and three of the nine \n",
       "victims were held that another student was arrested in connection with the school shootings of March <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span>. \n",
       "Authorities said little officially beyond confirming today's arrest. However, a source with knowledge of the \n",
       "investigation told the Minneapolis Star-Tribune that it was Louis Jourdain, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>-year old son of Red Lake Tribal \n",
       "Chairman Floyd Jourdain. It is not known at this time what charges will be laid or what led authorities to the boy \n",
       "but juvenile proceedings have begun in federal court. Question: According to the passage, while news was spreading \n",
       "about another arrest, funerals were being held for how many victims?\n",
       "Options: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'One'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Three'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Nine'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Four'</span><span style=\"font-weight: bold\">]</span>\n",
       "Answer: Four\n",
       "\n",
       "Question: Context: Brazil is the largest Roman Catholic country on Earth, and the Roman Catholic Church has \n",
       "consistently opposed the legalization of same-sex marriage in the country. The National Congress of Brazil has \n",
       "debated legalization for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> years, and such civil marriages are currently only legal in Rio Grande do Sul. The \n",
       "original bill was drafted by former mayor of São Paulo, Marta Suplicy. The proposed legislation, after being \n",
       "amended, is now in the hands of Roberto Jefferson. Protesters hope to collect a petition of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.2</span> million signatures \n",
       "to present to the National Congress in November. Question: Who will the protestors give their petition to?\n",
       "Options: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'The Roman Catholic Church'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Roberto Jefferson'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The National Congress of Brazil'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'The mayor of São </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Paulo'</span><span style=\"font-weight: bold\">]</span>\n",
       "Answer: The National Congress of Brazil\n",
       "\n",
       "Now I want you to label the following example:\n",
       "Question: Context: <span style=\"color: #008000; text-decoration-color: #008000\">\"The famous Greek lawyers, Sakis Kechagioglou and George Nikolakopoulos have been imprisoned in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the Athens' jail of Korydallus, as they were found guilty of graft and corruption. As a result of this, a big </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">scandal within the Greek legal community has been raised through the exposure of illegal actions that judges, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">lawyers, solicitors and attorneys have done during the previous years. A few weeks ago, after the information </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">published by the journalist Makis Triantafylopoulos in his popular Television show \"\"Zoungla\"\" in Alpha TV, the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">member of Parliament and lawyer, Petros Mantouvalos was abdicated as members of his office had been involved in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">illegal graft and corruption. Moreover, top judge Evangelos Kalousis is imprisoned as he found guilty of corruption</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and degenerate behaviour.\"</span> Question: Which of the following people is not a lawyer?\n",
       "Options: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Petros Mantouvalos'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Sakis Kechagioglou'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'George Nikolakopoulos'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Makis Triantafylopoulos'</span><span style=\"font-weight: bold\">]</span>\n",
       "Answer: \n",
       "</pre>\n"
      ],
      "text/plain": [
       "You are an expert at answering questions based on context. Your job is to answer the given question, using the \n",
       "options provided for each question. Choose the best answer for the question from among the options provided\n",
       "\n",
       "You will return the answer one element: \u001b[32m\"the correct label\"\u001b[0m\n",
       "\n",
       "\n",
       "Some examples with their output answers are provided below:\n",
       "\n",
       "Question: Context: \u001b[32m\"Widespread looting reportedly continued overnight, as law enforcement officers were not present\u001b[0m\n",
       "\u001b[32mon Bishkek's streets. Bishkek was described as sinking into a state of \"\u001b[0m\u001b[32m\"anarchy\"\u001b[0m\u001b[32m\" by one observer, as gangs of \u001b[0m\n",
       "\u001b[32mpeople roamed the streets and plundered stores of consumer goods. Several Bishkek residents blamed protesters from \u001b[0m\n",
       "\u001b[32mthe south for the lawlessness.\"\u001b[0m Question: Who did several of Bishkek’s residents think were responsible for the \n",
       "looting?\n",
       "Options: \u001b[1m[\u001b[0m\u001b[32m'Law enforcement officers'\u001b[0m, \u001b[32m'Store owners'\u001b[0m, \u001b[32m'Protesters'\u001b[0m, \u001b[32m'Teenagers'\u001b[0m\u001b[1m]\u001b[0m\n",
       "Answer: Protesters\n",
       "\n",
       "Question: Context: During his trip, Iwasaki ran into trouble on many occasions. He was robbed by pirates, attacked \n",
       "in Tibet by a rabid dog, escaped marriage in Nepal and was arrested in India. Question: Who attacked Iwasaki?\n",
       "Options: \u001b[1m[\u001b[0m\u001b[32m'His potential spouse'\u001b[0m, \u001b[32m'Pirates'\u001b[0m, \u001b[32m'A dog'\u001b[0m, \u001b[32m'Police'\u001b[0m\u001b[1m]\u001b[0m\n",
       "Answer: A dog\n",
       "\n",
       "Question: Context: Organisers of the protest said about \u001b[1;36m100\u001b[0m,\u001b[1;36m000\u001b[0m people turned up in German cities such as Berlin, \n",
       "Cologne, Hamburg, and Hanover. In Berlin, police estimated \u001b[1;36m6\u001b[0m,\u001b[1;36m500\u001b[0m protestors. Protests also took place in Paris, \n",
       "Sofia in Bulgaria, Vilnius in Lithuania, Valetta in Malta, Tallinn in Estonia, and Edinburgh and Glasgow in \n",
       "Scotland. In London, about \u001b[1;36m200\u001b[0m people protested outside some major copyright holders' offices. Last month, there \n",
       "were major protests in Poland when that country signed ACTA, which has led to the Polish government deciding not to\n",
       "ratify the agreement, for now. Latvia and Slovakia have both delayed the process of joining ACTA. Question: In \n",
       "response to the protests, which country did not move forward with their signed ACTA agreement?\n",
       "Options: \u001b[1m[\u001b[0m\u001b[32m'Germany'\u001b[0m, \u001b[32m'Poland'\u001b[0m, \u001b[32m'Scotland'\u001b[0m, \u001b[32m'Lithuania'\u001b[0m\u001b[1m]\u001b[0m\n",
       "Answer: Poland\n",
       "\n",
       "Question: Context: \u001b[32m\"The celebrations started with a special show by the world-renowned group Cirque du Soleil. It \u001b[0m\n",
       "\u001b[32mwas followed by the Istanbul State Symphony Orchestra, a Janissary band, and the singers Fatih Erkoç and Müslüm \u001b[0m\n",
       "\u001b[32mGürses. Then Whirling Dervishes took to the stage. Turkish diva Sezen Aksu performed with the Italian tenor \u001b[0m\n",
       "\u001b[32mAlessandro Safina and Greek singer Haris Alexiou. To finish, Turkish dance group Fire of Anatolia performed the \u001b[0m\n",
       "\u001b[32mshow \"\u001b[0m\u001b[32m\"Troy\"\u001b[0m\u001b[32m\".\"\u001b[0m Question: What was the second-last performance of the evening?\n",
       "Options: \u001b[1m[\u001b[0m\u001b[32m'Sezen Aksu, Alessandro Safina and Haris Alexiou'\u001b[0m, \u001b[32m'Fire of Anatolia'\u001b[0m, \u001b[32m'Whirling Dervishes'\u001b[0m, \u001b[32m'Fatih Erkoç\u001b[0m\n",
       "\u001b[32mand Müslüm Gürses'\u001b[0m\u001b[1m]\u001b[0m\n",
       "Answer: Sezen Aksu, Alessandro Safina and Haris Alexiou\n",
       "\n",
       "Question: Context: The terrified King Louis XVI, Queen Marie Antoinette their two young children \u001b[1m(\u001b[0m\u001b[1;36m11\u001b[0m year old Marie\n",
       "Therese and four year old Louis-Charles\u001b[1m)\u001b[0m and the King's sister, Madam Elizabeth, on the 6th October \u001b[1;36m1789\u001b[0m were \n",
       "forced back to Paris from Versailles by a mob of market women. In a carriage, they traveled back to Paris \n",
       "surrounded by a mob of people screaming and shouting threats against the King and Queen. The mob of people forced \n",
       "the King And Queen to have their carriage windows wide open. At one point a member of the mob waved the head of a \n",
       "royal guard killed at Versailles in front of the terrified Queen. Question: Which of the following was not forced \n",
       "upon the King and the Queen by the mob?\n",
       "Options: \u001b[1m[\u001b[0m\u001b[32m'The opening of their carriage windows'\u001b[0m, \u001b[32m'An abrupt exit from Versailles '\u001b[0m, \u001b[32m'A viewing of the guard’s \u001b[0m\n",
       "\u001b[32mbeheading'\u001b[0m, \u001b[32m'A trip back to Paris'\u001b[0m\u001b[1m]\u001b[0m\n",
       "Answer: A viewing of the guard’s beheading\n",
       "\n",
       "Question: Context: Martelly swore in a new Provisional Electoral Council \u001b[1m(\u001b[0mCEP\u001b[1m)\u001b[0m of nine members yesterday. It is \n",
       "Martelly's fifth CEP in four years. Last month a presidential commission recommended the prior CEP's resignation as\n",
       "part of a package of measures to move the country towards new elections. The commission was Martelly's response to \n",
       "widespread anti-regime protests that started in October. The sometimes-violent protests were triggered by failure \n",
       "to hold elections, some due since \u001b[1;36m2011\u001b[0m. Question: Which statement regarding the protests is not true?\n",
       "Options: \u001b[1m[\u001b[0m\u001b[32m'The presidential commission was a response to the protests'\u001b[0m, \u001b[32m'Overdue elections triggered the protests'\u001b[0m,\n",
       "\u001b[32m'Protests demanded the resignation of the prior CEP'\u001b[0m, \u001b[32m'The protests were sometimes violent'\u001b[0m\u001b[1m]\u001b[0m\n",
       "Answer: Protests demanded the resignation of the prior CEP\n",
       "\n",
       "Question: Context: A doctor who worked at Children's Hospital of Pittsburgh, Pennsylvania will be charged with \n",
       "aggravated murder after her mother was found dead in the trunk of her car Wednesday, authorities in Ohio say. Dr. \n",
       "Malar Balasubramanian, \u001b[1;36m29\u001b[0m, was found in Blue Ash, Ohio, a suburb approximately \u001b[1;36m15\u001b[0m miles north of Cincinnati lying \n",
       "on the ground beside the road in a T-shirt and underwear in an apparently heavily medicated state. She directed \n",
       "officers to her black Oldsmobile Intrigue which was \u001b[1;36m500\u001b[0m feet away. There, they found the body of Saroja \n",
       "Balasubramanian, \u001b[1;36m53\u001b[0m, covered with blood-stained blankets. Police said that the body appeared to have been there for\n",
       "about a day. Question: How was Dr. Malar Balasubramanian related to Saroja Balasubramanian?\n",
       "Options: \u001b[1m[\u001b[0m\u001b[32m'Sister'\u001b[0m, \u001b[32m'Daughter'\u001b[0m, \u001b[32m'Mother'\u001b[0m, \u001b[32m'Aunt'\u001b[0m\u001b[1m]\u001b[0m\n",
       "Answer: Daughter\n",
       "\n",
       "Question: Context: \u001b[32m\"The Irish government is stressing the urgency of parliamentary legislation to rectify the \u001b[0m\n",
       "\u001b[32msituation. \"\u001b[0m\u001b[32m\"It is now important from both a public health and criminal justice perspective that the legislation be\u001b[0m\n",
       "\u001b[32menacted as soon as possible\"\u001b[0m\u001b[32m\", said a government spokesperson. The Health Minister expressed concern both for the \u001b[0m\n",
       "\u001b[32mwelfare of individuals taking advantage of the temporary legality of the substances involved, and for drug-related \u001b[0m\n",
       "\u001b[32mconvictions handed down since the now-unconstitutional changes came into effect.\"\u001b[0m Question: What is the Irish \n",
       "government planning to do?\n",
       "Options: \u001b[1m[\u001b[0m\u001b[32m'Hand out convictions to drug offenders'\u001b[0m, \u001b[32m'Introduce more stringent laws on the permissibility of drugs'\u001b[0m,\n",
       "\u001b[32m'Relax laws on the permissibility of drugs'\u001b[0m, \u001b[32m'Decriminalise drugs'\u001b[0m\u001b[1m]\u001b[0m\n",
       "Answer: Introduce more stringent laws on the permissibility of drugs\n",
       "\n",
       "Question: Context: News spread in the Red Lake community today as funerals for Jeff Weise and three of the nine \n",
       "victims were held that another student was arrested in connection with the school shootings of March \u001b[1;36m21\u001b[0m. \n",
       "Authorities said little officially beyond confirming today's arrest. However, a source with knowledge of the \n",
       "investigation told the Minneapolis Star-Tribune that it was Louis Jourdain, \u001b[1;36m16\u001b[0m-year old son of Red Lake Tribal \n",
       "Chairman Floyd Jourdain. It is not known at this time what charges will be laid or what led authorities to the boy \n",
       "but juvenile proceedings have begun in federal court. Question: According to the passage, while news was spreading \n",
       "about another arrest, funerals were being held for how many victims?\n",
       "Options: \u001b[1m[\u001b[0m\u001b[32m'One'\u001b[0m, \u001b[32m'Three'\u001b[0m, \u001b[32m'Nine'\u001b[0m, \u001b[32m'Four'\u001b[0m\u001b[1m]\u001b[0m\n",
       "Answer: Four\n",
       "\n",
       "Question: Context: Brazil is the largest Roman Catholic country on Earth, and the Roman Catholic Church has \n",
       "consistently opposed the legalization of same-sex marriage in the country. The National Congress of Brazil has \n",
       "debated legalization for \u001b[1;36m10\u001b[0m years, and such civil marriages are currently only legal in Rio Grande do Sul. The \n",
       "original bill was drafted by former mayor of São Paulo, Marta Suplicy. The proposed legislation, after being \n",
       "amended, is now in the hands of Roberto Jefferson. Protesters hope to collect a petition of \u001b[1;36m1.2\u001b[0m million signatures \n",
       "to present to the National Congress in November. Question: Who will the protestors give their petition to?\n",
       "Options: \u001b[1m[\u001b[0m\u001b[32m'The Roman Catholic Church'\u001b[0m, \u001b[32m'Roberto Jefferson'\u001b[0m, \u001b[32m'The National Congress of Brazil'\u001b[0m, \u001b[32m'The mayor of São \u001b[0m\n",
       "\u001b[32mPaulo'\u001b[0m\u001b[1m]\u001b[0m\n",
       "Answer: The National Congress of Brazil\n",
       "\n",
       "Now I want you to label the following example:\n",
       "Question: Context: \u001b[32m\"The famous Greek lawyers, Sakis Kechagioglou and George Nikolakopoulos have been imprisoned in \u001b[0m\n",
       "\u001b[32mthe Athens' jail of Korydallus, as they were found guilty of graft and corruption. As a result of this, a big \u001b[0m\n",
       "\u001b[32mscandal within the Greek legal community has been raised through the exposure of illegal actions that judges, \u001b[0m\n",
       "\u001b[32mlawyers, solicitors and attorneys have done during the previous years. A few weeks ago, after the information \u001b[0m\n",
       "\u001b[32mpublished by the journalist Makis Triantafylopoulos in his popular Television show \"\u001b[0m\u001b[32m\"Zoungla\"\u001b[0m\u001b[32m\" in Alpha TV, the \u001b[0m\n",
       "\u001b[32mmember of Parliament and lawyer, Petros Mantouvalos was abdicated as members of his office had been involved in \u001b[0m\n",
       "\u001b[32millegal graft and corruption. Moreover, top judge Evangelos Kalousis is imprisoned as he found guilty of corruption\u001b[0m\n",
       "\u001b[32mand degenerate behaviour.\"\u001b[0m Question: Which of the following people is not a lawyer?\n",
       "Options: \u001b[1m[\u001b[0m\u001b[32m'Petros Mantouvalos'\u001b[0m, \u001b[32m'Sakis Kechagioglou'\u001b[0m, \u001b[32m'George Nikolakopoulos'\u001b[0m, \u001b[32m'Makis Triantafylopoulos'\u001b[0m\u001b[1m]\u001b[0m\n",
       "Answer: \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from autolabel import AutolabelDataset\n",
    "ds = AutolabelDataset(\"test.csv\", config=config)\n",
    "agent.plan(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd703025-54d8-4349-b0d6-736d2380e966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63c51d55a32f494ca494f3c5990d1a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-04 21:08:31 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87436 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:08:31 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87436 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:08:33 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88083 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:08:33 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88083 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:08:34 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88481 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:08:34 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88481 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:08:35 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 86934 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:08:35 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 86934 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:08:39 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88537 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:08:39 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88537 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:08:40 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 86983 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:08:40 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 86983 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:08:44 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87938 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:08:44 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87938 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:08:45 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88566 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:08:45 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88566 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:08:47 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88597 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:08:47 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88597 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:08:48 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87044 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:08:48 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87044 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:08:52 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88312 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:08:52 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88312 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:08:54 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88691 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:08:54 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88691 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:08:55 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87137 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:08:55 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87137 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:08:57 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 86706 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:08:57 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 86706 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:08:59 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87878 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:08:59 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87878 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:09:01 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87739 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:09:01 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87739 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:09:03 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88814 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:09:03 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88814 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:09:04 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87264 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:09:04 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87264 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:09:08 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87528 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:09:08 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87528 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:09:10 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87990 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:09:10 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87990 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:09:12 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88546 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:09:12 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88546 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:09:13 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87002 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:09:13 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87002 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:09:17 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87111 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:09:17 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87111 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:09:19 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88130 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:09:19 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88130 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:09:20 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88684 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:09:20 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88684 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:09:21 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87103 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:09:21 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87103 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:09:25 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88180 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:09:25 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88180 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:09:26 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88908 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:09:26 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88908 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:09:27 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87335 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:09:27 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87335 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:09:31 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88712 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:09:31 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88712 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:09:32 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87168 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:09:32 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87168 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:09:36 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87824 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:09:36 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87824 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:09:38 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88374 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:09:38 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88374 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:09:39 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 86830 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:09:39 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 86830 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:09:42 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87818 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:09:42 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87818 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:09:45 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87755 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:09:45 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87755 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:09:47 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87612 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:09:47 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87612 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:09:48 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88801 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:09:48 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88801 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:09:49 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87259 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:09:49 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87259 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:09:52 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 86847 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:09:52 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 86847 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:09:53 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88084 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:09:53 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88084 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:09:55 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89139 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:09:55 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89139 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:09:56 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87545 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:09:56 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87545 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:09:59 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 86961 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:09:59 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 86961 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:10:00 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87683 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:10:02 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88094 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:10:02 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88094 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:10:04 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89005 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:10:04 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89005 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:10:05 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87457 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:10:05 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87457 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:10:08 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89087 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:10:08 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89087 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:10:09 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87516 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:10:09 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87516 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:10:12 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 86697 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:10:12 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 86697 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:10:14 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87642 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:10:14 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87642 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:10:15 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88332 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:10:15 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88332 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:10:17 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89131 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:10:17 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89131 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:10:18 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87566 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:10:18 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87566 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:10:21 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87261 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:10:21 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87261 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:10:22 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87673 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:10:22 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87673 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:10:24 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88424 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:10:24 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88424 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:10:25 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 86875 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:10:25 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 86875 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:10:29 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87793 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:10:29 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87793 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:10:30 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88810 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:10:30 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 88810 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "2023-10-04 21:10:31 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87262 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-10-04 21:10:31 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 87262 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Actual Cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2864</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Actual Cost: \u001b[1;36m0.2864\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> accuracy </span>┃<span style=\"font-weight: bold\"> support </span>┃<span style=\"font-weight: bold\"> completion_rate </span>┃<span style=\"font-weight: bold\"> f1     </span>┃\n",
       "┡━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> 0.86     </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> 100     </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> 1.0             </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> 0.8842 </span>│\n",
       "└──────────┴─────────┴─────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1maccuracy\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1msupport\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mcompletion_rate\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mf1    \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[1;36m \u001b[0m\u001b[1;36m0.86    \u001b[0m\u001b[1;36m \u001b[0m│\u001b[1;36m \u001b[0m\u001b[1;36m100    \u001b[0m\u001b[1;36m \u001b[0m│\u001b[1;36m \u001b[0m\u001b[1;36m1.0            \u001b[0m\u001b[1;36m \u001b[0m│\u001b[1;36m \u001b[0m\u001b[1;36m0.8842\u001b[0m\u001b[1;36m \u001b[0m│\n",
       "└──────────┴─────────┴─────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = agent.run(ds, max_items=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
