{
    "task_name": "ToxicCommentClassification",
    "task_type": "classification",
    "dataset": {
        "label_column": "label",
        "delimiter": ","
    },
    "model": {
        "provider": "llama",
        "name": "/workspace/hf-trained-all-ds"
    },
    "embedding": {
        "provider": "openai"
    },
    "prompt": {
        "task_guidelines": "Your job is to correctly label the following into one of the following categories {labels}",
        "output_guidelines": "\\n",
        "labels": [
            "toxic",
            "not toxic"
        ],
        "few_shot_examples": "seed.csv",
        "few_shot_selection": "semantic_similarity",
        "few_shot_num": 0,
        "example_template": "{example}{label}"
    }
}