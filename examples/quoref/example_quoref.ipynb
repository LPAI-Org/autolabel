{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fe6e643-9453-4381-9445-bd471685fb96",
   "metadata": {},
   "source": [
    "## Exploring the [Quoref](https://huggingface.co/datasets/quoref) dataset using Autolabel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80110a5b-2b3e-45e2-a2da-f6fa00200dff",
   "metadata": {},
   "source": [
    "#### Setup the API Keys for providers that you want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92993c83-4473-4e05-9510-f543b070c7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# provide your own OpenAI API key here\n",
    "os.environ['OPENAI_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c246f85",
   "metadata": {},
   "source": [
    "#### Install the autolabel library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc181e31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: refuel-autolabel[openai] in /opt/homebrew/lib/python3.10/site-packages (0.0.1)\n",
      "Requirement already satisfied: loguru>=0.5.0 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (0.5.3)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (1.23.3)\n",
      "Requirement already satisfied: requests>=2.27.0 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (2.28.1)\n",
      "Requirement already satisfied: datasets>=2.7.0 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (2.11.0)\n",
      "Requirement already satisfied: langchain>=0.0.190 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (0.0.191)\n",
      "Requirement already satisfied: nervaluate>=0.1.8 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (0.1.8)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (1.5.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (1.1.2)\n",
      "Requirement already satisfied: tenacity>=8.2.2 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (8.2.2)\n",
      "Requirement already satisfied: SQLAlchemy==1.4.47 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (1.4.47)\n",
      "Requirement already satisfied: regex>=2023.6.3 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (2023.6.3)\n",
      "Requirement already satisfied: rich>=13.3.5 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (13.4.1)\n",
      "Requirement already satisfied: scipy>=1.10.1 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (1.10.1)\n",
      "Requirement already satisfied: pydantic>=1.10.9 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (1.10.9)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (1.13.0)\n",
      "Requirement already satisfied: matplotlib>=3.5.0 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (3.6.0)\n",
      "Requirement already satisfied: wget>=3.2 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (3.2)\n",
      "Requirement already satisfied: openai>=0.27.4 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (0.27.6)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /opt/homebrew/lib/python3.10/site-packages (from refuel-autolabel[openai]) (0.3.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/homebrew/lib/python3.10/site-packages (from datasets>=2.7.0->refuel-autolabel[openai]) (9.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/homebrew/lib/python3.10/site-packages (from datasets>=2.7.0->refuel-autolabel[openai]) (0.3.5.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/homebrew/lib/python3.10/site-packages (from datasets>=2.7.0->refuel-autolabel[openai]) (4.64.1)\n",
      "Requirement already satisfied: xxhash in /opt/homebrew/lib/python3.10/site-packages (from datasets>=2.7.0->refuel-autolabel[openai]) (3.1.0)\n",
      "Requirement already satisfied: multiprocess in /opt/homebrew/lib/python3.10/site-packages (from datasets>=2.7.0->refuel-autolabel[openai]) (0.70.13)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/homebrew/lib/python3.10/site-packages (from datasets>=2.7.0->refuel-autolabel[openai]) (2022.10.0)\n",
      "Requirement already satisfied: aiohttp in /opt/homebrew/lib/python3.10/site-packages (from datasets>=2.7.0->refuel-autolabel[openai]) (3.8.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /opt/homebrew/lib/python3.10/site-packages (from datasets>=2.7.0->refuel-autolabel[openai]) (0.14.1)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/lib/python3.10/site-packages (from datasets>=2.7.0->refuel-autolabel[openai]) (21.3)\n",
      "Requirement already satisfied: responses<0.19 in /opt/homebrew/lib/python3.10/site-packages (from datasets>=2.7.0->refuel-autolabel[openai]) (0.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/lib/python3.10/site-packages (from datasets>=2.7.0->refuel-autolabel[openai]) (6.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/homebrew/lib/python3.10/site-packages (from langchain>=0.0.190->refuel-autolabel[openai]) (4.0.2)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /opt/homebrew/lib/python3.10/site-packages (from langchain>=0.0.190->refuel-autolabel[openai]) (0.5.7)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /opt/homebrew/lib/python3.10/site-packages (from langchain>=0.0.190->refuel-autolabel[openai]) (2.8.4)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /opt/homebrew/lib/python3.10/site-packages (from langchain>=0.0.190->refuel-autolabel[openai]) (1.2.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.10/site-packages (from matplotlib>=3.5.0->refuel-autolabel[openai]) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/lib/python3.10/site-packages (from matplotlib>=3.5.0->refuel-autolabel[openai]) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/lib/python3.10/site-packages (from matplotlib>=3.5.0->refuel-autolabel[openai]) (4.37.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/homebrew/lib/python3.10/site-packages (from matplotlib>=3.5.0->refuel-autolabel[openai]) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/homebrew/lib/python3.10/site-packages (from matplotlib>=3.5.0->refuel-autolabel[openai]) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/homebrew/lib/python3.10/site-packages (from matplotlib>=3.5.0->refuel-autolabel[openai]) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/homebrew/lib/python3.10/site-packages (from matplotlib>=3.5.0->refuel-autolabel[openai]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.10/site-packages (from pandas>=1.3.0->refuel-autolabel[openai]) (2022.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/homebrew/lib/python3.10/site-packages (from pydantic>=1.10.9->refuel-autolabel[openai]) (4.3.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/homebrew/lib/python3.10/site-packages (from requests>=2.27.0->refuel-autolabel[openai]) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.10/site-packages (from requests>=2.27.0->refuel-autolabel[openai]) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/lib/python3.10/site-packages (from requests>=2.27.0->refuel-autolabel[openai]) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.10/site-packages (from requests>=2.27.0->refuel-autolabel[openai]) (2022.9.14)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/homebrew/lib/python3.10/site-packages (from rich>=13.3.5->refuel-autolabel[openai]) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/homebrew/lib/python3.10/site-packages (from rich>=13.3.5->refuel-autolabel[openai]) (2.15.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn>=1.0.0->refuel-autolabel[openai]) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn>=1.0.0->refuel-autolabel[openai]) (3.1.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.0->refuel-autolabel[openai]) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.0->refuel-autolabel[openai]) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.0->refuel-autolabel[openai]) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.0->refuel-autolabel[openai]) (1.3.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.0->refuel-autolabel[openai]) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /opt/homebrew/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.190->refuel-autolabel[openai]) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /opt/homebrew/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.190->refuel-autolabel[openai]) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.190->refuel-autolabel[openai]) (0.8.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets>=2.7.0->refuel-autolabel[openai]) (3.8.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/homebrew/lib/python3.10/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=13.3.5->refuel-autolabel[openai]) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.5.0->refuel-autolabel[openai]) (1.12.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/lib/python3.10/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.190->refuel-autolabel[openai]) (0.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install 'refuel-autolabel[openai]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5b1630",
   "metadata": {},
   "source": [
    "#### Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9382044e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading example dataset from https://autolabel-benchmarking.s3.us-west-2.amazonaws.com/quoref/seed.csv to seed.csv...\n",
      "Downloading example dataset from https://autolabel-benchmarking.s3.us-west-2.amazonaws.com/quoref/test.csv to test.csv...\n",
      "100% [........................................] [4384790/4384790] bytes\r"
     ]
    }
   ],
   "source": [
    "from autolabel import get_data\n",
    "\n",
    "get_data('quoref')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72542ae",
   "metadata": {},
   "source": [
    "This downloads two datasets:\n",
    "* `test.csv`: This is the larger dataset we are trying to label using LLMs\n",
    "* `seed.csv`: This is a small dataset where we already have human-provided labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb92a79",
   "metadata": {},
   "source": [
    "## Start the labeling process!\n",
    "\n",
    "Labeling with Autolabel is a 3-step process:\n",
    "* First, we specify a labeling configuration (see `config.json` below)\n",
    "* Next, we do a dry-run on our dataset using the LLM specified in `config.json` by running `agent.plan`\n",
    "* Finally, we run the labeling with `agent.run`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b014d1-f45c-4479-9acc-0d20870b1786",
   "metadata": {},
   "source": [
    "### First labeling run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c093fe91-3508-4140-8bd6-217034e3cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from autolabel import LabelingAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c93fae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the config\n",
    "with open('config_quoref.json', 'r') as f:\n",
    "     config = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dfc1f9",
   "metadata": {},
   "source": [
    "Let's review the configuration file below. You'll notice the following useful keys:\n",
    "* `task_type`: `named_entity_recognition` (since it's a named entity recognition task)\n",
    "* `model`: `{'provider': 'openai', 'name': 'gpt-3.5-turbo'}` (use a specific OpenAI model)\n",
    "* `prompt.task_guidelines`: `'You are an expert at extracting Person, Organization, Location, and Miscellaneous entities...` (how we describe the task to the LLM)\n",
    "* `prompt.labels`: `[\n",
    "            \"Location\",\n",
    "            \"Organization\",\n",
    "            \"Person\",\n",
    "            \"Miscellaneous\"\n",
    "        ]` (the full list of labels to choose from)\n",
    "* `prompt.few_shot_num`: 3 (how many labeled examples to provide to the LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "450ad645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_name': 'ExtractAnswerSubstring',\n",
       " 'task_type': 'named_entity_recognition',\n",
       " 'dataset': {'label_column': 'CategorizedLabels',\n",
       "  'text_column': 'example',\n",
       "  'delimiter': ','},\n",
       " 'model': {'provider': 'llama',\n",
       "  'name': '/workspace/hf-relevant-sampling-2483'},\n",
       " 'prompt': {'task_guidelines': 'Read the paragraph and answer the question at the end. The only category in this task is {labels}. Output a JSON with the key as \"Answer\" and its value as a list of substrings of the context.\\\\n',\n",
       "  'labels': ['Answer'],\n",
       "  'example_template': 'Example: {example}\\nOutput:\\n{CategorizedLabels}',\n",
       "  'few_shot_examples': 'seed.csv',\n",
       "  'few_shot_selection': 'semantic_similarity',\n",
       "  'few_shot_num': 2}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acb4a3de-fa84-4b94-b17a-7a6fac892a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-02 17:24:31 llm_engine.py:72] Initializing an LLM engine with config: model='/workspace/hf-relevant-sampling-2483', tokenizer='/workspace/hf-relevant-sampling-2483', tokenizer_mode=auto, trust_remote_code=False, dtype=torch.float16, download_dir=None, load_format=auto, tensor_parallel_size=1, seed=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-02 17:24:31 torch.distributed.distributed_c10d INFO: Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "2023-10-02 17:24:31 torch.distributed.distributed_c10d INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\n",
      "2023-10-02 17:24:32 torch.distributed.distributed_c10d INFO: Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "2023-10-02 17:24:32 torch.distributed.distributed_c10d INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 1 nodes.\n",
      "2023-10-02 17:24:32 torch.distributed.distributed_c10d INFO: Added key: store_based_barrier_key:3 to store for rank: 0\n",
      "2023-10-02 17:24:32 torch.distributed.distributed_c10d INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:3 with 1 nodes.\n",
      "2023-10-02 17:24:32 torch.distributed.distributed_c10d INFO: Added key: store_based_barrier_key:4 to store for rank: 0\n",
      "2023-10-02 17:24:32 torch.distributed.distributed_c10d INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:4 with 1 nodes.\n",
      "2023-10-02 17:24:32 torch.distributed.distributed_c10d INFO: Added key: store_based_barrier_key:5 to store for rank: 0\n",
      "2023-10-02 17:24:32 torch.distributed.distributed_c10d INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:5 with 1 nodes.\n",
      "2023-10-02 17:24:32 torch.distributed.distributed_c10d INFO: Added key: store_based_barrier_key:6 to store for rank: 0\n",
      "2023-10-02 17:24:32 torch.distributed.distributed_c10d INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:6 with 1 nodes.\n",
      "2023-10-02 17:24:32 torch.distributed.distributed_c10d INFO: Added key: store_based_barrier_key:7 to store for rank: 0\n",
      "2023-10-02 17:24:32 torch.distributed.distributed_c10d INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:7 with 1 nodes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-02 17:25:20 llm_engine.py:199] # GPU blocks: 1468, # CPU blocks: 327\n"
     ]
    }
   ],
   "source": [
    "# create an agent for labeling\n",
    "agent = LabelingAgent(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92667a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a559077fcd466e9efd25cb3c741a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┌──────────────────────────┬──────┐\n",
       "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Total Estimated Cost     </span>│<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> $0.0 </span>│\n",
       "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Number of Examples       </span>│<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> 2000 </span>│\n",
       "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Average cost per example </span>│<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> $0.0 </span>│\n",
       "└──────────────────────────┴──────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┌──────────────────────────┬──────┐\n",
       "│\u001b[1;35m \u001b[0m\u001b[1;35mTotal Estimated Cost    \u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;32m \u001b[0m\u001b[1;32m$0.0\u001b[0m\u001b[1;32m \u001b[0m│\n",
       "│\u001b[1;35m \u001b[0m\u001b[1;35mNumber of Examples      \u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;32m \u001b[0m\u001b[1;32m2000\u001b[0m\u001b[1;32m \u001b[0m│\n",
       "│\u001b[1;35m \u001b[0m\u001b[1;35mAverage cost per example\u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;32m \u001b[0m\u001b[1;32m$0.0\u001b[0m\u001b[1;32m \u001b[0m│\n",
       "└──────────────────────────┴──────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────────────────── </span>Prompt Example<span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ──────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────────────────── \u001b[0mPrompt Example\u001b[92m ──────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "    <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">s</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #000000; text-decoration-color: #000000\">INST</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\"> &lt;&lt;SYS&gt;&gt;</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    Read the paragraph and answer the question at the end. The only category in this task is Answer. Output a JSON </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">with the key as </span><span style=\"color: #008000; text-decoration-color: #008000\">\"Answer\"</span><span style=\"color: #000000; text-decoration-color: #000000\"> and its value as a list of substrings of the context.\\nYou will return the answer in JSON </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">format, where keys are the above categories and values is a list of substrings corresponding to that category.</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">Example: Context: Novelists and writers have captured much of the color and challenge in their immigrant lives </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">through their writings.Regarding Irish women in the 19th century, there were numerous novels and short stories by </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">Harvey O'Higgins, Peter McCorry, Bernard O'Reilly and Sarah Orne Jewett that emphasize emancipation from Old World </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">controls, new opportunities and expansiveness of the immigrant experience.On the other hand, Hladnik studies three </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">popular novels of the late 19th century that warned Slovenes not to immigrate to the dangerous new world of the </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">United States.Jewish American writer Anzia Yezierska wrote her novel Bread Givers </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1925</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\"> to explore such themes as </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">Russian-Jewish immigration in the early 20th century, the tension between Old and New World Yiddish culture, and </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">women's experience of immigration. A well established author Yezierska focused on the Jewish struggle to escape the</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">ghetto and enter middle- and upper-class America. In the novel, the heroine, Sara Smolinsky, escape from New York </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">City's </span><span style=\"color: #008000; text-decoration-color: #008000\">\"down-town ghetto\"</span><span style=\"color: #000000; text-decoration-color: #000000\"> by breaking tradition. She quits her job at the family store and soon becomes engaged to </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">a rich real-estate magnate. She graduates college and takes a high-prestige job teaching public school. Finally </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">Sara restores her broken links to family and religion.The Swedish author Vilhelm Moberg in the mid-20th century </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">wrote a series of four novels describing one Swedish family's migration from Småland to Minnesota in the late 19th </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">century, a destiny shared by almost one million people. The author emphasizes the authenticity of the experiences </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">as depicted </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #000000; text-decoration-color: #000000\">although he did change names</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">. These novels have been translated into English </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #000000; text-decoration-color: #000000\">The Emigrants, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1951</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">Unto a Good Land, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1954</span><span style=\"color: #000000; text-decoration-color: #000000\">, The Settlers, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1961</span><span style=\"color: #000000; text-decoration-color: #000000\">, The Last Letter Home, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1961</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">. The musical Kristina från Duvemåla by </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">ex-ABBA members Björn Ulvaeus and Benny Andersson is based on this story.The Immigrant is a musical by Steven </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">Alper, Sarah Knapp, and Mark Harelik. The show is based on the story of Harelik's grandparents, Matleh and Haskell </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">Harelik, who traveled to Galveston, Texas in </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1909</span><span style=\"color: #000000; text-decoration-color: #000000\">.</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\"> Question: What was the full name of the person that writes about Sara Smolinsky?</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">Output:</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Answer\"</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Anzia Yezierska\"</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]}</span>\n",
       "\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">Example: Context: Young Judy Bellaire has trouble fitting in at school, causing trouble by introducing her jazzy </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">style into music class and being expelled as a result.  Returning home to her dysfunctional and financially </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">challenged family, where her playwright father, actress mother, and beautiful elder sister, Sylvia compete for </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">attention along with the funny Russian maid, Olga and the hunky cook, Ricky, who is not-so-secretly in love with </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">Sylvia.  Judy foils her father's attempt to ship her off to Europe by escaping from the ship and then trying out </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">for a musical show as a blackface singer, taking advantage of her love of jazz to enchant the show's producer, who </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">hires her and makes her a star of his new show.  Meanwhile, Ricky cuts a record, musically expressing his love for </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">Sylvia.  Nevertheless, Sylvia is forced into engagement with another man.</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">When the distraught parents discover their younger daughter is appearing in a musical show, Sylvia rejoins her </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">love, who is also appearing in the show.  Finally, all the cast members are reunited, including the Russian maid, </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">who finds her lost love, Boris.  The movie's happy ending includes an extravagant stage piece with gorgeously </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">attired chorus girls, happily reunited parents and child, and the happy kiss between Sylvia and Ricky, who is now </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">the producer of a successful musical show.</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\"> Question: What are the professions of the parents who are distraught over Judy participating in a show?</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">Output:</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Answer\"</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"playwright\"</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">\"actress\"</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]}</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    &lt;&lt;SYS&gt;</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "    Example: Context: The film was written by Pulitzer Prize winner Ira Berkow, and narrated by actor Dustin \n",
       "Hoffman.  It was directed by Peter Miller, a documentary filmmaker known for his previous films A Class Apart, \n",
       "Sacco and Vanzetti, and The Internationale.Dustin Hoffman does not normally narrate films, and initially turned \n",
       "down the project.  But when he looked at the script, he changed his mind, saying: <span style=\"color: #008000; text-decoration-color: #008000\">\"Oh, this is about bigotry and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">overcoming anti-Semitism, about discrimination and these issues that I grew up with, that really matters to me\"</span>.The\n",
       "film opens with a clip from the <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1980</span> satirical comedy film Airplane!, in which a flight attendant is asked by a \n",
       "passenger if she has anything light to read.  She responds by offering an ultra-thin leaflet, saying:  <span style=\"color: #008000; text-decoration-color: #008000\">\"How about </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">this leaflet, Famous Jewish Sports Legends?\"</span>The stereotype of Jews as non-athletic, as well as anti-semitism, are \n",
       "two issues that many Jewish baseball players faced and had to overcome.  Noted anti-semite Henry Ford wrote on May \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1920</span>:  <span style=\"color: #008000; text-decoration-color: #008000\">\"If fans wish to know the trouble with American baseball they have it in three words—too much Jew.\"</span>  A \n",
       "number of early Jewish ballplayers changed their names, so that it would not be apparent that they were Jewish.The \n",
       "movie discusses the key Jewish ballplayers in each decade since baseball started in the 1860s, and how that helped \n",
       "Jews assimilate and counteract the stereotype of Jews as cerebral but non-athletic.  The film is in part about \n",
       "Jewish immigration and assimilation into American society, bigotry against Jews, the passing on of Jewish \n",
       "traditions even during assimilation, heroism, and the breaking of Jewish stereotypes.Director Miller said:\n",
       "\n",
       "At its heart, this is a film about overcoming stereotypes. Bigotry against Jews has faded a great deal <span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       " Question: What roll did Dustin Hoffman have in the film?\n",
       "Output:\n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">INST</span><span style=\"font-weight: bold\">]</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "    \u001b[1m<\u001b[0m\u001b[1;95ms\u001b[0m\u001b[39m>\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mINST\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m <<SYS>>\u001b[0m\n",
       "\u001b[39m    Read the paragraph and answer the question at the end. The only category in this task is Answer. Output a JSON \u001b[0m\n",
       "\u001b[39mwith the key as \u001b[0m\u001b[32m\"Answer\"\u001b[0m\u001b[39m and its value as a list of substrings of the context.\\nYou will return the answer in JSON \u001b[0m\n",
       "\u001b[39mformat, where keys are the above categories and values is a list of substrings corresponding to that category.\u001b[0m\n",
       "\u001b[39mExample: Context: Novelists and writers have captured much of the color and challenge in their immigrant lives \u001b[0m\n",
       "\u001b[39mthrough their writings.Regarding Irish women in the 19th century, there were numerous novels and short stories by \u001b[0m\n",
       "\u001b[39mHarvey O'Higgins, Peter McCorry, Bernard O'Reilly and Sarah Orne Jewett that emphasize emancipation from Old World \u001b[0m\n",
       "\u001b[39mcontrols, new opportunities and expansiveness of the immigrant experience.On the other hand, Hladnik studies three \u001b[0m\n",
       "\u001b[39mpopular novels of the late 19th century that warned Slovenes not to immigrate to the dangerous new world of the \u001b[0m\n",
       "\u001b[39mUnited States.Jewish American writer Anzia Yezierska wrote her novel Bread Givers \u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;36m1925\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m to explore such themes as \u001b[0m\n",
       "\u001b[39mRussian-Jewish immigration in the early 20th century, the tension between Old and New World Yiddish culture, and \u001b[0m\n",
       "\u001b[39mwomen's experience of immigration. A well established author Yezierska focused on the Jewish struggle to escape the\u001b[0m\n",
       "\u001b[39mghetto and enter middle- and upper-class America. In the novel, the heroine, Sara Smolinsky, escape from New York \u001b[0m\n",
       "\u001b[39mCity's \u001b[0m\u001b[32m\"down-town ghetto\"\u001b[0m\u001b[39m by breaking tradition. She quits her job at the family store and soon becomes engaged to \u001b[0m\n",
       "\u001b[39ma rich real-estate magnate. She graduates college and takes a high-prestige job teaching public school. Finally \u001b[0m\n",
       "\u001b[39mSara restores her broken links to family and religion.The Swedish author Vilhelm Moberg in the mid-20th century \u001b[0m\n",
       "\u001b[39mwrote a series of four novels describing one Swedish family's migration from Småland to Minnesota in the late 19th \u001b[0m\n",
       "\u001b[39mcentury, a destiny shared by almost one million people. The author emphasizes the authenticity of the experiences \u001b[0m\n",
       "\u001b[39mas depicted \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39malthough he did change names\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m. These novels have been translated into English \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mThe Emigrants, \u001b[0m\u001b[1;36m1951\u001b[0m\u001b[39m, \u001b[0m\n",
       "\u001b[39mUnto a Good Land, \u001b[0m\u001b[1;36m1954\u001b[0m\u001b[39m, The Settlers, \u001b[0m\u001b[1;36m1961\u001b[0m\u001b[39m, The Last Letter Home, \u001b[0m\u001b[1;36m1961\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m. The musical Kristina från Duvemåla by \u001b[0m\n",
       "\u001b[39mex-ABBA members Björn Ulvaeus and Benny Andersson is based on this story.The Immigrant is a musical by Steven \u001b[0m\n",
       "\u001b[39mAlper, Sarah Knapp, and Mark Harelik. The show is based on the story of Harelik's grandparents, Matleh and Haskell \u001b[0m\n",
       "\u001b[39mHarelik, who traveled to Galveston, Texas in \u001b[0m\u001b[1;36m1909\u001b[0m\u001b[39m.\u001b[0m\n",
       "\u001b[39m Question: What was the full name of the person that writes about Sara Smolinsky?\u001b[0m\n",
       "\u001b[39mOutput:\u001b[0m\n",
       "\u001b[1;39m{\u001b[0m\u001b[32m\"Answer\"\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m\"Anzia Yezierska\"\u001b[0m\u001b[1;39m]\u001b[0m\u001b[1;39m}\u001b[0m\n",
       "\n",
       "\u001b[39mExample: Context: Young Judy Bellaire has trouble fitting in at school, causing trouble by introducing her jazzy \u001b[0m\n",
       "\u001b[39mstyle into music class and being expelled as a result.  Returning home to her dysfunctional and financially \u001b[0m\n",
       "\u001b[39mchallenged family, where her playwright father, actress mother, and beautiful elder sister, Sylvia compete for \u001b[0m\n",
       "\u001b[39mattention along with the funny Russian maid, Olga and the hunky cook, Ricky, who is not-so-secretly in love with \u001b[0m\n",
       "\u001b[39mSylvia.  Judy foils her father's attempt to ship her off to Europe by escaping from the ship and then trying out \u001b[0m\n",
       "\u001b[39mfor a musical show as a blackface singer, taking advantage of her love of jazz to enchant the show's producer, who \u001b[0m\n",
       "\u001b[39mhires her and makes her a star of his new show.  Meanwhile, Ricky cuts a record, musically expressing his love for \u001b[0m\n",
       "\u001b[39mSylvia.  Nevertheless, Sylvia is forced into engagement with another man.\u001b[0m\n",
       "\u001b[39mWhen the distraught parents discover their younger daughter is appearing in a musical show, Sylvia rejoins her \u001b[0m\n",
       "\u001b[39mlove, who is also appearing in the show.  Finally, all the cast members are reunited, including the Russian maid, \u001b[0m\n",
       "\u001b[39mwho finds her lost love, Boris.  The movie's happy ending includes an extravagant stage piece with gorgeously \u001b[0m\n",
       "\u001b[39mattired chorus girls, happily reunited parents and child, and the happy kiss between Sylvia and Ricky, who is now \u001b[0m\n",
       "\u001b[39mthe producer of a successful musical show.\u001b[0m\n",
       "\u001b[39m Question: What are the professions of the parents who are distraught over Judy participating in a show?\u001b[0m\n",
       "\u001b[39mOutput:\u001b[0m\n",
       "\u001b[1;39m{\u001b[0m\u001b[32m\"Answer\"\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m\"playwright\"\u001b[0m\u001b[39m, \u001b[0m\u001b[32m\"actress\"\u001b[0m\u001b[1;39m]\u001b[0m\u001b[1;39m}\u001b[0m\n",
       "\u001b[39m    <<SYS>\u001b[0m\u001b[1m>\u001b[0m\n",
       "    Example: Context: The film was written by Pulitzer Prize winner Ira Berkow, and narrated by actor Dustin \n",
       "Hoffman.  It was directed by Peter Miller, a documentary filmmaker known for his previous films A Class Apart, \n",
       "Sacco and Vanzetti, and The Internationale.Dustin Hoffman does not normally narrate films, and initially turned \n",
       "down the project.  But when he looked at the script, he changed his mind, saying: \u001b[32m\"Oh, this is about bigotry and \u001b[0m\n",
       "\u001b[32movercoming anti-Semitism, about discrimination and these issues that I grew up with, that really matters to me\"\u001b[0m.The\n",
       "film opens with a clip from the \u001b[1;36m1980\u001b[0m satirical comedy film Airplane!, in which a flight attendant is asked by a \n",
       "passenger if she has anything light to read.  She responds by offering an ultra-thin leaflet, saying:  \u001b[32m\"How about \u001b[0m\n",
       "\u001b[32mthis leaflet, Famous Jewish Sports Legends?\"\u001b[0mThe stereotype of Jews as non-athletic, as well as anti-semitism, are \n",
       "two issues that many Jewish baseball players faced and had to overcome.  Noted anti-semite Henry Ford wrote on May \n",
       "\u001b[1;36m22\u001b[0m, \u001b[1;36m1920\u001b[0m:  \u001b[32m\"If fans wish to know the trouble with American baseball they have it in three words—too much Jew.\"\u001b[0m  A \n",
       "number of early Jewish ballplayers changed their names, so that it would not be apparent that they were Jewish.The \n",
       "movie discusses the key Jewish ballplayers in each decade since baseball started in the 1860s, and how that helped \n",
       "Jews assimilate and counteract the stereotype of Jews as cerebral but non-athletic.  The film is in part about \n",
       "Jewish immigration and assimilation into American society, bigotry against Jews, the passing on of Jewish \n",
       "traditions even during assimilation, heroism, and the breaking of Jewish stereotypes.Director Miller said:\n",
       "\n",
       "At its heart, this is a film about overcoming stereotypes. Bigotry against Jews has faded a great deal \u001b[33m...\u001b[0m\n",
       " Question: What roll did Dustin Hoffman have in the film?\n",
       "Output:\n",
       "\u001b[1m[\u001b[0m\u001b[35m/\u001b[0m\u001b[95mINST\u001b[0m\u001b[1m]\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dry-run -- this tells us how much this will cost and shows an example prompt\n",
    "from autolabel import AutolabelDataset\n",
    "ds = AutolabelDataset(\"test.csv\", config=config)\n",
    "agent.plan(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd703025-54d8-4349-b0d6-736d2380e966",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebb6734b56454f86875ec4990edddb07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-02 17:27:38 autolabel.tasks.named_entity_recognition ERROR: unterminated string literal (detected at line 1) (<unknown>, line 1). Could not parse LLM output: {'Answer': ['L\\\\'Andromeda']}\n",
      "2023-10-02 17:27:41 autolabel.tasks.named_entity_recognition ERROR: unterminated string literal (detected at line 1) (<unknown>, line 1). Could not parse LLM output: {'Answer': ['O\\\\'Brien']}\n",
      "2023-10-02 17:28:56 autolabel.tasks.named_entity_recognition ERROR: Error parsing LLM response: ['college'], Error: list indices must be integers or slices, not str\n",
      "2023-10-02 17:29:16 autolabel.tasks.named_entity_recognition ERROR: unterminated string literal (detected at line 1) (<unknown>, line 1). Could not parse LLM output: {'Answer': ['O\\\\'Brien']}\n",
      "2023-10-02 17:29:40 autolabel.tasks.named_entity_recognition ERROR: Error parsing LLM response: ['Cohen'], Error: list indices must be integers or slices, not str\n",
      "2023-10-02 17:31:04 autolabel.tasks.named_entity_recognition ERROR: Error parsing LLM response: ['Love'], Error: list indices must be integers or slices, not str\n",
      "2023-10-02 17:31:44 autolabel.tasks.named_entity_recognition ERROR: Error parsing LLM response: ['Louise'], Error: list indices must be integers or slices, not str\n",
      "2023-10-02 17:32:09 autolabel.tasks.named_entity_recognition ERROR: unterminated string literal (detected at line 1) (<unknown>, line 1). Could not parse LLM output: {'Answer': ['O\\\\'Conner']}\n",
      "2023-10-02 17:32:25 autolabel.tasks.named_entity_recognition ERROR: unterminated string literal (detected at line 1) (<unknown>, line 1). Could not parse LLM output: {'Answer': ['Colin O\\\\'Brien']}\n",
      "2023-10-02 17:33:57 autolabel.tasks.named_entity_recognition ERROR: Error parsing LLM response:    ['New York Central Railroad'], Error: list indices must be integers or slices, not str\n",
      "2023-10-02 17:34:21 autolabel.tasks.named_entity_recognition ERROR: unterminated string literal (detected at line 1) (<unknown>, line 1). Could not parse LLM output: {'Answer': ['L\\\\'incoronazione di Poppea']}\n",
      "2023-10-02 17:34:59 autolabel.tasks.named_entity_recognition ERROR: unterminated string literal (detected at line 1) (<unknown>, line 1). Could not parse LLM output: {'Answer': ['O\\\\'Conner']}\n",
      "2023-10-02 17:36:03 autolabel.tasks.named_entity_recognition ERROR: Error parsing LLM response: ['Federal Reserve'], Error: list indices must be integers or slices, not str\n",
      "2023-10-02 17:37:00 autolabel.tasks.named_entity_recognition ERROR: unterminated string literal (detected at line 1) (<unknown>, line 1). Could not parse LLM output: {'Answer': ['a farmer\\\\'s dog']}\n",
      "2023-10-02 17:38:33 autolabel.tasks.named_entity_recognition ERROR: invalid syntax. Perhaps you forgot a comma? (<unknown>, line 1). Could not parse LLM output: {'Answer': ['L\\\\'enfant et les sortil\\u00e8ges']}\n",
      "2023-10-02 17:38:34 autolabel.tasks.named_entity_recognition ERROR: Error parsing LLM response:    ['Tzigane'], Error: list indices must be integers or slices, not str\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "error",
     "evalue": "missing ), unterminated subpattern at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# now, do the actual labeling\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_items\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/autolabel/src/autolabel/labeler.py:228\u001b[0m, in \u001b[0;36mLabelingAgent.run\u001b[0;34m(self, dataset, output_name, max_items, start_index, additional_metrics, skip_eval)\u001b[0m\n\u001b[1;32m    226\u001b[0m llm_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_all_annotations()\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39mgt_labels:\n\u001b[0;32m--> 228\u001b[0m     eval_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mllm_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgt_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mllm_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m eval_result:\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# This is a row wise metric\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(m\u001b[38;5;241m.\u001b[39mvalue, \u001b[38;5;28mlist\u001b[39m):\n",
      "File \u001b[0;32m/workspace/autolabel/src/autolabel/tasks/named_entity_recognition.py:293\u001b[0m, in \u001b[0;36mNamedEntityRecognitionTask.eval\u001b[0;34m(self, llm_labels, gt_labels, additional_metrics)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     llm_labels: List[LLMAnnotation],\n\u001b[1;32m    280\u001b[0m     gt_labels: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m    281\u001b[0m     additional_metrics: Optional[List[BaseMetric]] \u001b[38;5;241m=\u001b[39m [],\n\u001b[1;32m    282\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[MetricResult]:\n\u001b[1;32m    283\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate the LLM generated labels by comparing them against ground truth\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \n\u001b[1;32m    285\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03m        List[MetricResult]: list of metrics and corresponding values\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     gt_labels \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_text_spans(\n\u001b[1;32m    295\u001b[0m             json\u001b[38;5;241m.\u001b[39mloads(gt_labels[index]), llm_labels[index]\u001b[38;5;241m.\u001b[39mcurr_sample\u001b[38;5;241m.\u001b[39mdecode()\n\u001b[1;32m    296\u001b[0m         )\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(gt_labels))\n\u001b[1;32m    298\u001b[0m     ]\n\u001b[1;32m    300\u001b[0m     (\n\u001b[1;32m    301\u001b[0m         curr_gt_labels,\n\u001b[1;32m    302\u001b[0m         curr_llm_labels,\n\u001b[1;32m    303\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_labels_predictions_with_threshold(\n\u001b[1;32m    304\u001b[0m         gt_labels, llm_labels, \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-inf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    305\u001b[0m     )\n\u001b[1;32m    307\u001b[0m     entity_types_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;28mset\u001b[39m(\n\u001b[1;32m    309\u001b[0m             [\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    314\u001b[0m         )\n\u001b[1;32m    315\u001b[0m     )\n",
      "File \u001b[0;32m/workspace/autolabel/src/autolabel/tasks/named_entity_recognition.py:294\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     llm_labels: List[LLMAnnotation],\n\u001b[1;32m    280\u001b[0m     gt_labels: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m    281\u001b[0m     additional_metrics: Optional[List[BaseMetric]] \u001b[38;5;241m=\u001b[39m [],\n\u001b[1;32m    282\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[MetricResult]:\n\u001b[1;32m    283\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate the LLM generated labels by comparing them against ground truth\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \n\u001b[1;32m    285\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03m        List[MetricResult]: list of metrics and corresponding values\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    293\u001b[0m     gt_labels \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 294\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_text_spans\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgt_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurr_sample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(gt_labels))\n\u001b[1;32m    298\u001b[0m     ]\n\u001b[1;32m    300\u001b[0m     (\n\u001b[1;32m    301\u001b[0m         curr_gt_labels,\n\u001b[1;32m    302\u001b[0m         curr_llm_labels,\n\u001b[1;32m    303\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_labels_predictions_with_threshold(\n\u001b[1;32m    304\u001b[0m         gt_labels, llm_labels, \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-inf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    305\u001b[0m     )\n\u001b[1;32m    307\u001b[0m     entity_types_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;28mset\u001b[39m(\n\u001b[1;32m    309\u001b[0m             [\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    314\u001b[0m         )\n\u001b[1;32m    315\u001b[0m     )\n",
      "File \u001b[0;32m/workspace/autolabel/src/autolabel/tasks/named_entity_recognition.py:138\u001b[0m, in \u001b[0;36mNamedEntityRecognitionTask.add_text_spans\u001b[0;34m(self, raw_output, input)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m processed_output:\n\u001b[1;32m    137\u001b[0m     text \u001b[38;5;241m=\u001b[39m label[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 138\u001b[0m     matches \u001b[38;5;241m=\u001b[39m [i\u001b[38;5;241m.\u001b[39mstart() \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinditer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    139\u001b[0m     count \u001b[38;5;241m=\u001b[39m frequency_count[text]\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# if count of the named entity is greater than the number of matches, default to last found match\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/re.py:247\u001b[0m, in \u001b[0;36mfinditer\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfinditer\u001b[39m(pattern, string, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    243\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return an iterator over all non-overlapping matches in the\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;124;03m    string.  For each match, the iterator returns a Match object.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \n\u001b[1;32m    246\u001b[0m \u001b[38;5;124;03m    Empty matches are included in the result.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfinditer(string)\n",
      "File \u001b[0;32m/usr/lib/python3.10/re.py:303\u001b[0m, in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sre_compile\u001b[38;5;241m.\u001b[39misstring(pattern):\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst argument must be string or compiled pattern\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 303\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43msre_compile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (flags \u001b[38;5;241m&\u001b[39m DEBUG):\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(_cache) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m _MAXCACHE:\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;66;03m# Drop the oldest item\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/sre_compile.py:788\u001b[0m, in \u001b[0;36mcompile\u001b[0;34m(p, flags)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isstring(p):\n\u001b[1;32m    787\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m p\n\u001b[0;32m--> 788\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[43msre_parse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    790\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/sre_parse.py:955\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(str, flags, state)\u001b[0m\n\u001b[1;32m    952\u001b[0m state\u001b[38;5;241m.\u001b[39mstr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 955\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[43m_parse_sub\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mSRE_FLAG_VERBOSE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Verbose:\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;66;03m# the VERBOSE flag was switched on inside the pattern.  to be\u001b[39;00m\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;66;03m# on the safe side, we'll parse the whole thing again...\u001b[39;00m\n\u001b[1;32m    959\u001b[0m     state \u001b[38;5;241m=\u001b[39m State()\n",
      "File \u001b[0;32m/usr/lib/python3.10/sre_parse.py:444\u001b[0m, in \u001b[0;36m_parse_sub\u001b[0;34m(source, state, verbose, nested)\u001b[0m\n\u001b[1;32m    442\u001b[0m start \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mtell()\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m     itemsappend(\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnested\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnested\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitems\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sourcematch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/sre_parse.py:843\u001b[0m, in \u001b[0;36m_parse\u001b[0;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[1;32m    841\u001b[0m p \u001b[38;5;241m=\u001b[39m _parse_sub(source, state, sub_verbose, nested \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    842\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m source\u001b[38;5;241m.\u001b[39mmatch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 843\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m source\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmissing ), unterminated subpattern\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    844\u001b[0m                        source\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;241m-\u001b[39m start)\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m group \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    846\u001b[0m     state\u001b[38;5;241m.\u001b[39mclosegroup(group, p)\n",
      "\u001b[0;31merror\u001b[0m: missing ), unterminated subpattern at position 0"
     ]
    }
   ],
   "source": [
    "# now, do the actual labeling\n",
    "ds = agent.run(ds, max_items=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e1901d",
   "metadata": {},
   "source": [
    "We are at 88.9% accuracy when labeling the first 100 examples. Let's see if we can use confidence scores to improve accuracy further by removing the less confident examples from our labeled set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
