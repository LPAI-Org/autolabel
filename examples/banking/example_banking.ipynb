{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fe6e643-9453-4381-9445-bd471685fb96",
   "metadata": {},
   "source": [
    "# Labeling the [banking](https://huggingface.co/datasets/banking77) dataset using Autolabel\n",
    "\n",
    "This is a multi-class classification task where the input are customer service queries and we have to correctly label them with one of 77 intents. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aacac4ae-c7f9-4dee-be3a-a2a6bfa099fa",
   "metadata": {},
   "source": [
    "## Install Autolabel\n",
    "Plus, setup your OpenAI API key, since we'll be using `gpt-3.5-turbo` as our LLM for labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc19059-2f63-44b7-9a32-8b38a11249aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'refuel-autolabel[openai]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbdeca2f-dd20-4634-b3f8-1b3ed45c4705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# provide your own OpenAI API key here\n",
    "os.environ['OPENAI_API_KEY'] = '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'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8eb09918-494a-42ef-86a7-df93b3ce4284",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Download the dataset\n",
    "\n",
    "This dataset is available to install via Autolabel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4c116ce-3294-45c2-9158-eac929f03a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autolabel import get_data\n",
    "\n",
    "get_data('banking')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f038fcc-9ec0-4f2d-b84d-2e963656c6bd",
   "metadata": {},
   "source": [
    "This downloads two datasets:\n",
    "* `test.csv`: This is the larger dataset we are trying to label using LLMs\n",
    "* `seed.csv`: This is a small dataset where we already have human-provided labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84b014d1-f45c-4479-9acc-0d20870b1786",
   "metadata": {},
   "source": [
    "## Start the labeling process!\n",
    "\n",
    "Labeling with Autolabel is a 3-step process:\n",
    "* First, we specify a labeling configuration (see `config.json` below)\n",
    "* Next, we do a dry-run on our dataset using the LLM specified in `config.json` by running `agent.plan`\n",
    "* Finally, we run the labeling with `agent.run`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33d47b67-0718-4289-bb59-989d851d09ed",
   "metadata": {},
   "source": [
    "### First labeling run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c093fe91-3508-4140-8bd6-217034e3cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from autolabel import LabelingAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c93fae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the config\n",
    "with open('config_banking.json', 'r') as f:\n",
    "     config = json.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fad4e85-d598-413d-9b01-9690653a05ad",
   "metadata": {},
   "source": [
    "Let's review the configuration file below. You'll notice the following useful keys:\n",
    "* `task_type`: `classification` (since it's a classification task)\n",
    "* `model`: `{'provider': 'openai', 'name': 'gpt-3.5-turbo'}` (use a specific OpenAI model)\n",
    "* `prompt.task_guidelines`: `'You are an expert at understanding bank customers support complaints and queries...` (how we describe the task to the LLM)\n",
    "* `prompt.labels`: `['age_limit', 'apple_pay_or_google_pay', 'atm_support', ...]` (the full list of labels to choose from)\n",
    "* `prompt.few_shot_num`: 10 (how many labeled examples to provide to the LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a3610fd-721e-44de-9b2c-2cd73ec86bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_name': 'BankingComplaintsClassification',\n",
       " 'task_type': 'classification',\n",
       " 'dataset': {'label_column': 'label', 'delimiter': ','},\n",
       " 'model': {'provider': 'llama', 'name': '/workspace/hf-trained-nonchat'},\n",
       " 'embedding': {'provider': 'openai'},\n",
       " 'prompt': {'task_guidelines': 'Your job is to correctly label the following into one of the following categories {labels}',\n",
       "  'output_guidelines': '\\\\n',\n",
       "  'labels': ['activate_my_card',\n",
       "   'age_limit',\n",
       "   'apple_pay_or_google_pay',\n",
       "   'atm_support',\n",
       "   'automatic_top_up',\n",
       "   'balance_not_updated_after_bank_transfer',\n",
       "   'balance_not_updated_after_cheque_or_cash_deposit',\n",
       "   'beneficiary_not_allowed',\n",
       "   'cancel_transfer',\n",
       "   'card_about_to_expire',\n",
       "   'card_acceptance',\n",
       "   'card_arrival',\n",
       "   'card_delivery_estimate',\n",
       "   'card_linking',\n",
       "   'card_not_working',\n",
       "   'card_payment_fee_charged',\n",
       "   'card_payment_not_recognised',\n",
       "   'card_payment_wrong_exchange_rate',\n",
       "   'card_swallowed',\n",
       "   'cash_withdrawal_charge',\n",
       "   'cash_withdrawal_not_recognised',\n",
       "   'change_pin',\n",
       "   'compromised_card',\n",
       "   'contactless_not_working',\n",
       "   'country_support',\n",
       "   'declined_card_payment',\n",
       "   'declined_cash_withdrawal',\n",
       "   'declined_transfer',\n",
       "   'direct_debit_payment_not_recognised',\n",
       "   'disposable_card_limits',\n",
       "   'edit_personal_details',\n",
       "   'exchange_charge',\n",
       "   'exchange_rate',\n",
       "   'exchange_via_app',\n",
       "   'extra_charge_on_statement',\n",
       "   'failed_transfer',\n",
       "   'fiat_currency_support',\n",
       "   'get_disposable_virtual_card',\n",
       "   'get_physical_card',\n",
       "   'getting_spare_card',\n",
       "   'getting_virtual_card',\n",
       "   'lost_or_stolen_card',\n",
       "   'lost_or_stolen_phone',\n",
       "   'order_physical_card',\n",
       "   'passcode_forgotten',\n",
       "   'pending_card_payment',\n",
       "   'pending_cash_withdrawal',\n",
       "   'pending_top_up',\n",
       "   'pending_transfer',\n",
       "   'pin_blocked',\n",
       "   'receiving_money',\n",
       "   'Refund_not_showing_up',\n",
       "   'request_refund',\n",
       "   'reverted_card_payment?',\n",
       "   'supported_cards_and_currencies',\n",
       "   'terminate_account',\n",
       "   'top_up_by_bank_transfer_charge',\n",
       "   'top_up_by_card_charge',\n",
       "   'top_up_by_cash_or_cheque',\n",
       "   'top_up_failed',\n",
       "   'top_up_limits',\n",
       "   'top_up_reverted',\n",
       "   'topping_up_by_card',\n",
       "   'transaction_charged_twice',\n",
       "   'transfer_fee_charged',\n",
       "   'transfer_into_account',\n",
       "   'transfer_not_received_by_recipient',\n",
       "   'transfer_timing',\n",
       "   'unable_to_verify_identity',\n",
       "   'verify_my_identity',\n",
       "   'verify_source_of_funds',\n",
       "   'verify_top_up',\n",
       "   'virtual_card_not_working',\n",
       "   'visa_or_mastercard',\n",
       "   'why_verify_identity',\n",
       "   'wrong_amount_of_cash_received',\n",
       "   'wrong_exchange_rate_for_cash_withdrawal'],\n",
       "  'few_shot_examples': 'seed.csv',\n",
       "  'few_shot_selection': 'semantic_similarity',\n",
       "  'few_shot_num': 10,\n",
       "  'example_template': '{example}{label}'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acb4a3de-fa84-4b94-b17a-7a6fac892a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 08-25 00:49:28 llm_engine.py:70] Initializing an LLM engine with config: model='/workspace/hf-trained-nonchat', tokenizer='/workspace/hf-trained-nonchat', tokenizer_mode=auto, trust_remote_code=False, dtype=torch.float16, use_dummy_weights=False, download_dir=None, use_np_weights=False, tensor_parallel_size=1, seed=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-25 00:49:28 torch.distributed.distributed_c10d INFO: Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "2023-08-25 00:49:28 torch.distributed.distributed_c10d INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\n",
      "2023-08-25 00:49:29 torch.distributed.distributed_c10d INFO: Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "2023-08-25 00:49:29 torch.distributed.distributed_c10d INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 1 nodes.\n",
      "2023-08-25 00:49:29 torch.distributed.distributed_c10d INFO: Added key: store_based_barrier_key:3 to store for rank: 0\n",
      "2023-08-25 00:49:29 torch.distributed.distributed_c10d INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:3 with 1 nodes.\n",
      "2023-08-25 00:49:29 torch.distributed.distributed_c10d INFO: Added key: store_based_barrier_key:4 to store for rank: 0\n",
      "2023-08-25 00:49:29 torch.distributed.distributed_c10d INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:4 with 1 nodes.\n",
      "2023-08-25 00:49:29 torch.distributed.distributed_c10d INFO: Added key: store_based_barrier_key:5 to store for rank: 0\n",
      "2023-08-25 00:49:29 torch.distributed.distributed_c10d INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:5 with 1 nodes.\n",
      "2023-08-25 00:49:29 torch.distributed.distributed_c10d INFO: Added key: store_based_barrier_key:6 to store for rank: 0\n",
      "2023-08-25 00:49:29 torch.distributed.distributed_c10d INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:6 with 1 nodes.\n",
      "2023-08-25 00:49:29 torch.distributed.distributed_c10d INFO: Added key: store_based_barrier_key:7 to store for rank: 0\n",
      "2023-08-25 00:49:29 torch.distributed.distributed_c10d INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:7 with 1 nodes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 08-25 00:50:11 llm_engine.py:196] # GPU blocks: 1463, # CPU blocks: 327\n"
     ]
    }
   ],
   "source": [
    "# create an agent for labeling\n",
    "agent = LabelingAgent(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92667a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb918eeea48d4054aaee926a767c3d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "\"clamp_min_scalar_cpu\" not implemented for 'Half'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautolabel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutolabelDataset\n\u001b[1;32m      3\u001b[0m ds \u001b[38;5;241m=\u001b[39m AutolabelDataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, config\u001b[38;5;241m=\u001b[39mconfig)\n\u001b[0;32m----> 4\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/autolabel/src/autolabel/labeler.py:341\u001b[0m, in \u001b[0;36mLabelingAgent.plan\u001b[0;34m(self, dataset, max_items, start_index)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_i \u001b[38;5;129;01min\u001b[39;00m track(\n\u001b[1;32m    335\u001b[0m     dataset\u001b[38;5;241m.\u001b[39minputs[:input_limit],\n\u001b[1;32m    336\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating Prompts...\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    337\u001b[0m     console\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconsole,\n\u001b[1;32m    338\u001b[0m ):\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;66;03m# TODO: Check if this needs to use the example selector\u001b[39;00m\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexample_selector:\n\u001b[0;32m--> 341\u001b[0m         examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexample_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_examples\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_i\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m         examples \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/prompts/example_selector/semantic_similarity.py:54\u001b[0m, in \u001b[0;36mSemanticSimilarityExampleSelector.select_examples\u001b[0;34m(self, input_variables)\u001b[0m\n\u001b[1;32m     52\u001b[0m     input_variables \u001b[38;5;241m=\u001b[39m {key: input_variables[key] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_keys}\n\u001b[1;32m     53\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(sorted_values(input_variables))\n\u001b[0;32m---> 54\u001b[0m example_docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Get the examples from the metadata.\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# This assumes that examples are stored in metadata.\u001b[39;00m\n\u001b[1;32m     57\u001b[0m examples \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mdict\u001b[39m(e\u001b[38;5;241m.\u001b[39mmetadata) \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m example_docs]\n",
      "File \u001b[0;32m/workspace/autolabel/src/autolabel/few_shot/vector_store.py:266\u001b[0m, in \u001b[0;36mVectorStoreWrapper.similarity_search\u001b[0;34m(self, query, k, filter, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity_search\u001b[39m(\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    253\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    257\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    258\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run semantic similarity search.\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;124;03m        query (str): Query text to search for.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m        List[Document]: List of documents most similar to the query text.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m     docs_and_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_with_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_and_scores]\n",
      "File \u001b[0;32m/workspace/autolabel/src/autolabel/few_shot/vector_store.py:286\u001b[0m, in \u001b[0;36mVectorStoreWrapper.similarity_search_with_score\u001b[0;34m(self, query, k, filter, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run semantic similarity search and retrieve distances.\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;124;03m    query (str): Query text to search for.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03m        text with distance in float.\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    285\u001b[0m query_embeddings \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_embeddings([query])[\u001b[38;5;241m0\u001b[39m]])\n\u001b[0;32m--> 286\u001b[0m result_ids_and_scores \u001b[38;5;241m=\u001b[39m \u001b[43msemantic_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcorpus_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_corpus_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m result_ids \u001b[38;5;241m=\u001b[39m [result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorpus_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m result_ids_and_scores[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m    292\u001b[0m scores \u001b[38;5;241m=\u001b[39m [result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m result_ids_and_scores[\u001b[38;5;241m0\u001b[39m]]\n",
      "File \u001b[0;32m/workspace/autolabel/src/autolabel/few_shot/vector_store.py:92\u001b[0m, in \u001b[0;36msemantic_search\u001b[0;34m(query_embeddings, corpus_embeddings, query_chunk_size, corpus_chunk_size, top_k, score_function)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m query_start_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(query_embeddings), query_chunk_size):\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m# Iterate over chunks of the corpus\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m corpus_start_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(corpus_embeddings), corpus_chunk_size):\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;66;03m# Compute cosine similarities\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m         cos_scores \u001b[38;5;241m=\u001b[39m \u001b[43mscore_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m            \u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[43mquery_start_idx\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_start_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mquery_chunk_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcorpus_embeddings\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcorpus_start_idx\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus_start_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcorpus_chunk_size\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;66;03m# Get top-k scores\u001b[39;00m\n\u001b[1;32m    100\u001b[0m         cos_scores_top_k_values, cos_scores_top_k_idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtopk(\n\u001b[1;32m    101\u001b[0m             cos_scores,\n\u001b[1;32m    102\u001b[0m             \u001b[38;5;28mmin\u001b[39m(top_k, \u001b[38;5;28mlen\u001b[39m(cos_scores[\u001b[38;5;241m0\u001b[39m])),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[38;5;28msorted\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    106\u001b[0m         )\n",
      "File \u001b[0;32m/workspace/autolabel/src/autolabel/few_shot/vector_store.py:52\u001b[0m, in \u001b[0;36mcos_sim\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(b\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     50\u001b[0m     b \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 52\u001b[0m a_norm \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m b_norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mnormalize(b, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmm(a_norm, b_norm\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4660\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(input, p, dim, eps, out)\u001b[0m\n\u001b[1;32m   4658\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(normalize, (\u001b[38;5;28minput\u001b[39m, out), \u001b[38;5;28minput\u001b[39m, p\u001b[38;5;241m=\u001b[39mp, dim\u001b[38;5;241m=\u001b[39mdim, eps\u001b[38;5;241m=\u001b[39meps, out\u001b[38;5;241m=\u001b[39mout)\n\u001b[1;32m   4659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4660\u001b[0m     denom \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclamp_min\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mexpand_as(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m   4661\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m/\u001b[39m denom\n\u001b[1;32m   4662\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \"clamp_min_scalar_cpu\" not implemented for 'Half'"
     ]
    }
   ],
   "source": [
    "# dry-run -- this tells us how much this will cost and shows an example prompt\n",
    "from autolabel import AutolabelDataset\n",
    "ds = AutolabelDataset(\"test.csv\", config=config)\n",
    "agent.plan(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79625069-8762-4bfd-896f-e836bbea2bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<class 'openai.api_resources.embedding.Embedding'>, model='text-embedding-ada-002', deployment='text-embedding-ada-002', openai_api_version='', openai_api_base='', openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key='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', openai_organization='', allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=6, request_timeout=None, headers=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.example_selector.vectorstore._embedding_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd703025-54d8-4349-b0d6-736d2380e966",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158ba2371c16417fbef3ae8aff83bca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">classification_report:\n",
       "                                         precision    recall  f1-score   support\n",
       "\n",
       "                       activate_my_card       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "    direct_debit_payment_not_recognised       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.00</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.00</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.00</span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "              extra_charge_on_statement       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.50</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.00</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.67</span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "                    order_physical_card       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "                      terminate_account       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.00</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.00</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.00</span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "wrong_exchange_rate_for_cash_withdrawal       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "\n",
       "                               accuracy                           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.60</span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "                              macro avg       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.42</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.50</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.44</span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "                           weighted avg       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.50</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.60</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.53</span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "classification_report:\n",
       "                                         precision    recall  f1-score   support\n",
       "\n",
       "                       activate_my_card       \u001b[1;36m0.00\u001b[0m      \u001b[1;36m0.00\u001b[0m      \u001b[1;36m0.00\u001b[0m         \u001b[1;36m0\u001b[0m\n",
       "    direct_debit_payment_not_recognised       \u001b[1;36m1.00\u001b[0m      \u001b[1;36m1.00\u001b[0m      \u001b[1;36m1.00\u001b[0m         \u001b[1;36m1\u001b[0m\n",
       "              extra_charge_on_statement       \u001b[1;36m0.50\u001b[0m      \u001b[1;36m1.00\u001b[0m      \u001b[1;36m0.67\u001b[0m         \u001b[1;36m1\u001b[0m\n",
       "                    order_physical_card       \u001b[1;36m0.00\u001b[0m      \u001b[1;36m0.00\u001b[0m      \u001b[1;36m0.00\u001b[0m         \u001b[1;36m1\u001b[0m\n",
       "                      terminate_account       \u001b[1;36m1.00\u001b[0m      \u001b[1;36m1.00\u001b[0m      \u001b[1;36m1.00\u001b[0m         \u001b[1;36m1\u001b[0m\n",
       "wrong_exchange_rate_for_cash_withdrawal       \u001b[1;36m0.00\u001b[0m      \u001b[1;36m0.00\u001b[0m      \u001b[1;36m0.00\u001b[0m         \u001b[1;36m1\u001b[0m\n",
       "\n",
       "                               accuracy                           \u001b[1;36m0.60\u001b[0m         \u001b[1;36m5\u001b[0m\n",
       "                              macro avg       \u001b[1;36m0.42\u001b[0m      \u001b[1;36m0.50\u001b[0m      \u001b[1;36m0.44\u001b[0m         \u001b[1;36m5\u001b[0m\n",
       "                           weighted avg       \u001b[1;36m0.50\u001b[0m      \u001b[1;36m0.60\u001b[0m      \u001b[1;36m0.53\u001b[0m         \u001b[1;36m5\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Actual Cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0052</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Actual Cost: \u001b[1;36m0.0052\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> accuracy </span>┃<span style=\"font-weight: bold\"> support </span>┃<span style=\"font-weight: bold\"> completion_rate </span>┃\n",
       "┡━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> 0.6      </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> 5       </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> 1.0             </span>│\n",
       "└──────────┴─────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1maccuracy\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1msupport\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mcompletion_rate\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[1;36m \u001b[0m\u001b[1;36m0.6     \u001b[0m\u001b[1;36m \u001b[0m│\u001b[1;36m \u001b[0m\u001b[1;36m5      \u001b[0m\u001b[1;36m \u001b[0m│\u001b[1;36m \u001b[0m\u001b[1;36m1.0            \u001b[0m\u001b[1;36m \u001b[0m│\n",
       "└──────────┴─────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-13 09:27:15 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89386 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-08-13 09:27:15 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89386 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-13 09:27:19 openai INFO: error_code=rate_limit_exceeded error_message='Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89026 / min. Contact us through our help center at help.openai.com if you continue to have issues.' error_param=None error_type=tokens message='OpenAI API error received' stream_error=False\n",
      "2023-08-13 09:27:19 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-etZVkYhAIYGmLcxLmarMmAPo on tokens per min. Limit: 90000 / min. Current: 89026 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Cost: 0.1017\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> accuracy </span>┃<span style=\"font-weight: bold\"> support </span>┃<span style=\"font-weight: bold\"> completion_rate </span>┃\n",
       "┡━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> 0.7677   </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> 100     </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> 0.99            </span>│\n",
       "└──────────┴─────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1maccuracy\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1msupport\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mcompletion_rate\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[1;36m \u001b[0m\u001b[1;36m0.7677  \u001b[0m\u001b[1;36m \u001b[0m│\u001b[1;36m \u001b[0m\u001b[1;36m100    \u001b[0m\u001b[1;36m \u001b[0m│\u001b[1;36m \u001b[0m\u001b[1;36m0.99           \u001b[0m\u001b[1;36m \u001b[0m│\n",
       "└──────────┴─────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now, do the actual labeling\n",
    "ds = agent.run(ds, max_items=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "73037ec4-0282-4058-8336-c81f6dc6e711",
   "metadata": {},
   "source": [
    "We are at 76% accuracy when labeling the first 100 examples. Let's see if we can use confidence scores to improve accuracy further by removing the less confident examples from our labeled set."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d7645ab",
   "metadata": {},
   "source": [
    "## Compute confidence scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fbc1264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start computing confidence scores (using Refuel's LLMs)\n",
    "os.environ['REFUEL_API_KEY'] = 'sk-xxxxxxxxxxxx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a923034-b41b-47bb-91a7-7332a33f151f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set `compute_confidence` -> True\n",
    "config[\"model\"][\"compute_confidence\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1998f5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = LabelingAgent(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "119e6f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Prompts... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100/100 0:00:24 0:00:00\n",
      "┌──────────────────────────┬─────────┐\n",
      "│ Total Estimated Cost     │ $6.6836 │\n",
      "│ Number of Examples       │ 1998    │\n",
      "│ Average cost per example │ $0.0033 │\n",
      "└──────────────────────────┴─────────┘\n",
      "──────────────────────────────── Prompt Example ────────────────────────────────\n",
      "You are an expert at understanding bank customers support complaints and queries.\n",
      "Your job is to correctly classify the provided input example into one of the following categories.\n",
      "Categories:\n",
      "activate_my_card\n",
      "age_limit\n",
      "apple_pay_or_google_pay\n",
      "atm_support\n",
      "automatic_top_up\n",
      "balance_not_updated_after_bank_transfer\n",
      "balance_not_updated_after_cheque_or_cash_deposit\n",
      "beneficiary_not_allowed\n",
      "cancel_transfer\n",
      "card_about_to_expire\n",
      "card_acceptance\n",
      "card_arrival\n",
      "card_delivery_estimate\n",
      "card_linking\n",
      "card_not_working\n",
      "card_payment_fee_charged\n",
      "card_payment_not_recognised\n",
      "card_payment_wrong_exchange_rate\n",
      "card_swallowed\n",
      "cash_withdrawal_charge\n",
      "cash_withdrawal_not_recognised\n",
      "change_pin\n",
      "compromised_card\n",
      "contactless_not_working\n",
      "country_support\n",
      "declined_card_payment\n",
      "declined_cash_withdrawal\n",
      "declined_transfer\n",
      "direct_debit_payment_not_recognised\n",
      "disposable_card_limits\n",
      "edit_personal_details\n",
      "exchange_charge\n",
      "exchange_rate\n",
      "exchange_via_app\n",
      "extra_charge_on_statement\n",
      "failed_transfer\n",
      "fiat_currency_support\n",
      "get_disposable_virtual_card\n",
      "get_physical_card\n",
      "getting_spare_card\n",
      "getting_virtual_card\n",
      "lost_or_stolen_card\n",
      "lost_or_stolen_phone\n",
      "order_physical_card\n",
      "passcode_forgotten\n",
      "pending_card_payment\n",
      "pending_cash_withdrawal\n",
      "pending_top_up\n",
      "pending_transfer\n",
      "pin_blocked\n",
      "receiving_money\n",
      "Refund_not_showing_up\n",
      "request_refund\n",
      "reverted_card_payment?\n",
      "supported_cards_and_currencies\n",
      "terminate_account\n",
      "top_up_by_bank_transfer_charge\n",
      "top_up_by_card_charge\n",
      "top_up_by_cash_or_cheque\n",
      "top_up_failed\n",
      "top_up_limits\n",
      "top_up_reverted\n",
      "topping_up_by_card\n",
      "transaction_charged_twice\n",
      "transfer_fee_charged\n",
      "transfer_into_account\n",
      "transfer_not_received_by_recipient\n",
      "transfer_timing\n",
      "unable_to_verify_identity\n",
      "verify_my_identity\n",
      "verify_source_of_funds\n",
      "verify_top_up\n",
      "virtual_card_not_working\n",
      "visa_or_mastercard\n",
      "why_verify_identity\n",
      "wrong_amount_of_cash_received\n",
      "wrong_exchange_rate_for_cash_withdrawal\n",
      "\n",
      "You will answer with just the the correct output label and nothing else.\n",
      "\n",
      "Some examples with their output answers are provided below:\n",
      "\n",
      "Input: I would like to delete my account please.\n",
      "Output: terminate_account\n",
      "\n",
      "Input: Can you help me get rid of my account?\n",
      "Output: terminate_account\n",
      "\n",
      "Input: Help me cancel my transaction\n",
      "Output: cancel_transfer\n",
      "\n",
      "Input: I need to cancel a purchase I made.\n",
      "Output: request_refund\n",
      "\n",
      "Input: I want to change my personal details.\n",
      "Output: edit_personal_details\n",
      "\n",
      "Input: How can I withdraw money?\n",
      "Output: atm_support\n",
      "\n",
      "Input: How do I do a successful transfer to an account?\n",
      "Output: beneficiary_not_allowed\n",
      "\n",
      "Input: Why wasn't I able to transfer to another account?\n",
      "Output: beneficiary_not_allowed\n",
      "\n",
      "Input: Can my daughter open an account?\n",
      "Output: age_limit\n",
      "\n",
      "Input: I need to update my current address\n",
      "Output: edit_personal_details\n",
      "\n",
      "Now I want you to label the following example:\n",
      "Input: I want to close my account\n",
      "Output: \n",
      "────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "from autolabel import AutolabelDataset\n",
    "ds = AutolabelDataset(\"test.csv\", config=config)\n",
    "agent.plan(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63c74705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ad306191e44a60918b09abae371b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 22:59:21 openai INFO: error_code=None error_message='That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 603d90627ab4c936108e1009bec434b8 in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False\n",
      "2023-06-13 22:59:21 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 603d90627ab4c936108e1009bec434b8 in your message.).\n",
      "2023-06-13 23:00:06 openai INFO: error_code=None error_message='That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9ddebe0bfe2beb3935b21d667d5905ec in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False\n",
      "2023-06-13 23:00:06 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9ddebe0bfe2beb3935b21d667d5905ec in your message.).\n",
      "2023-06-13 23:01:04 openai INFO: error_code=None error_message='That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 109247fedbf578ce085155e22c6f5196 in your message.)' error_param=None error_type=server_error message='OpenAI API error received' stream_error=False\n",
      "2023-06-13 23:01:04 langchain.chat_models.openai WARNING: Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 109247fedbf578ce085155e22c6f5196 in your message.).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: auroc: 0.8737\n",
      "Actual Cost: 0.1356\n",
      "┏━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
      "┃ support ┃ threshold ┃ accuracy ┃ completion_rate ┃\n",
      "┡━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
      "│ 100     │ -inf      │ 0.74     │ 1.0             │\n",
      "│ 1       │ 0.9999    │ 1.0      │ 0.01            │\n",
      "│ 12      │ 0.9992    │ 1.0      │ 0.12            │\n",
      "│ 13      │ 0.9991    │ 0.9231   │ 0.13            │\n",
      "│ 41      │ 0.9916    │ 0.9756   │ 0.41            │\n",
      "│ 42      │ 0.9912    │ 0.9524   │ 0.42            │\n",
      "│ 43      │ 0.9912    │ 0.9535   │ 0.43            │\n",
      "│ 44      │ 0.9901    │ 0.9318   │ 0.44            │\n",
      "│ 48      │ 0.9873    │ 0.9375   │ 0.48            │\n",
      "│ 49      │ 0.9872    │ 0.9184   │ 0.49            │\n",
      "│ 63      │ 0.9695    │ 0.9365   │ 0.63            │\n",
      "│ 64      │ 0.9664    │ 0.9219   │ 0.64            │\n",
      "│ 66      │ 0.9601    │ 0.9242   │ 0.66            │\n",
      "│ 67      │ 0.9587    │ 0.9104   │ 0.67            │\n",
      "│ 68      │ 0.9523    │ 0.9118   │ 0.68            │\n",
      "│ 69      │ 0.95      │ 0.8986   │ 0.69            │\n",
      "│ 74      │ 0.9305    │ 0.9054   │ 0.74            │\n",
      "│ 75      │ 0.9066    │ 0.8933   │ 0.75            │\n",
      "│ 76      │ 0.905     │ 0.8947   │ 0.76            │\n",
      "│ 77      │ 0.9046    │ 0.8831   │ 0.77            │\n",
      "│ 78      │ 0.8996    │ 0.8846   │ 0.78            │\n",
      "│ 81      │ 0.8786    │ 0.8519   │ 0.81            │\n",
      "│ 82      │ 0.8764    │ 0.8537   │ 0.82            │\n",
      "│ 84      │ 0.8657    │ 0.8333   │ 0.84            │\n",
      "│ 86      │ 0.8547    │ 0.8372   │ 0.86            │\n",
      "│ 89      │ 0.8004    │ 0.809    │ 0.89            │\n",
      "│ 90      │ 0.7594    │ 0.8111   │ 0.9             │\n",
      "│ 93      │ 0.7036    │ 0.7849   │ 0.93            │\n",
      "│ 94      │ 0.6932    │ 0.7872   │ 0.94            │\n",
      "│ 100     │ 0.2895    │ 0.74     │ 1.0             │\n",
      "└─────────┴───────────┴──────────┴─────────────────┘\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total number of failures: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Total number of failures: \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = agent.run(ds, max_items=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62dc2f6f-29e0-4b32-be7b-e10d99698c51",
   "metadata": {},
   "source": [
    "Looking at the table above, we can see that if we set the confidence threshold at `0.9305`, we are able to label at 90% accuracy and getting a completion rate of 74%. This means, we would ignore all the data points where confidence score is less than `0.9305` (which would end up being around 26% of all samples). This would, however, guarantee a very high quality labeled dataset for us. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
